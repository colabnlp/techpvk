{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "meetpvk_working_23_03_of Vkt_TinyImageNet_StarterNotebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/techpvk/techpvk/blob/master/meetpvk_working_23_03_of_Vkt_TinyImageNet_StarterNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "I4th9KTGttp2",
        "colab_type": "code",
        "outputId": "48c299d8-1738-471a-ad6e-23fe81b486d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# List and Clear the Data first\n",
        "!ls\n",
        "!rm -rf sample_data tiny-imagenet-200\ttiny-imagenet-200.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.h5    session4_vkt_model240319.h5    tiny-imagenet-200\n",
            "model.yaml  session4_vkt_model240319.yaml  tiny-imagenet-200.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Atw96-N2TqIJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "496d11dc-71cf-4262-de1c-d545f5980cba"
      },
      "cell_type": "code",
      "source": [
        "# list content after the clearing data\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.h5    session4_vkt_model240319.h5\n",
            "model.yaml  session4_vkt_model240319.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2-uxInsGaQTb",
        "colab_type": "code",
        "outputId": "97ac4b54-94f5-4eda-c30f-c8f7882421c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Download the file\n",
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-25 09:37:23--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  20.7MB/s    in 15s     \n",
            "\n",
            "2019-03-25 09:37:37 (16.3 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "phm86ZULdPa1",
        "colab_type": "code",
        "outputId": "f4ec0bac-2007-442f-b493-b462abfa48bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#unzip and list\n",
        "!unzip -qq 'tiny-imagenet-200.zip'\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.h5    session4_vkt_model240319.h5    tiny-imagenet-200\n",
            "model.yaml  session4_vkt_model240319.yaml  tiny-imagenet-200.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7l_PCFURg9x_",
        "colab_type": "code",
        "outputId": "803d0b06-1935-45ad-d07a-806261c35dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# import the required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import six\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from __future__ import division\n",
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Activation,\n",
        "    Dense,\n",
        "    Flatten,\n",
        "    Dropout\n",
        ")\n",
        "from keras.layers.convolutional import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    AveragePooling2D\n",
        ")\n",
        "from keras.layers.merge import add\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.models import Model, load_model, model_from_yaml"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "r7SjAhI2Jskn",
        "colab_type": "code",
        "outputId": "f0ebbf98-2904-46f3-9b10-5df402de1e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "val_data.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>val_0.JPEG</td>\n",
              "      <td>n03444034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>val_1.JPEG</td>\n",
              "      <td>n04067472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>val_2.JPEG</td>\n",
              "      <td>n04070727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>val_3.JPEG</td>\n",
              "      <td>n02808440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>val_4.JPEG</td>\n",
              "      <td>n02808440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>val_5.JPEG</td>\n",
              "      <td>n04399382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>val_6.JPEG</td>\n",
              "      <td>n04179913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>val_7.JPEG</td>\n",
              "      <td>n02823428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>val_8.JPEG</td>\n",
              "      <td>n04146614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>val_9.JPEG</td>\n",
              "      <td>n02226429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         File      Class\n",
              "0  val_0.JPEG  n03444034\n",
              "1  val_1.JPEG  n04067472\n",
              "2  val_2.JPEG  n04070727\n",
              "3  val_3.JPEG  n02808440\n",
              "4  val_4.JPEG  n02808440\n",
              "5  val_5.JPEG  n04399382\n",
              "6  val_6.JPEG  n04179913\n",
              "7  val_7.JPEG  n02823428\n",
              "8  val_8.JPEG  n04146614\n",
              "9  val_9.JPEG  n02226429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "wRYLyZtwKKDp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use Augmentaion parameters as required.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    zoom_range = 0.3,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True\n",
        "    )\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "igYtU_VSKXto",
        "colab_type": "code",
        "outputId": "bd402854-a413-4a1c-dfbb-a8bd88a31c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(32, 32), color_mode='rgb', \n",
        "                                                    batch_size=200, class_mode='categorical', shuffle=True, seed=42)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UBRfC4SdKbca",
        "colab_type": "code",
        "outputId": "8c001624-c6ed-41b6-b4b4-a1c4a8b953ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(32, 32),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=200, shuffle=True, seed=42)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4AfmUc4gxPg6",
        "colab_type": "code",
        "outputId": "b0fa6ecc-9992-4af6-d359-f576117c00f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(train_generator)\n",
        "x_batch.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "CsK7MXV_wZS8",
        "colab_type": "code",
        "outputId": "377be0a5-e5bc-467f-c760-d656c8d317a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot Generator images.  ** Re-run the cell to view different set of images.\n",
        "\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "\n",
        "for i in range(8):\n",
        "    sub = fig.add_subplot(2, 4, i + 1)\n",
        "    sub.imshow(x_batch[i,:,:], interpolation='nearest')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAv8AAAExCAYAAADr8c17AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCw5rI6TRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1008x360 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pfHaHidXMWM3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _bn_relu(input):\n",
        "    \"\"\"Helper to build a BN -> relu block\n",
        "    \"\"\"\n",
        "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
        "    return Activation(\"relu\")(norm)\n",
        "\n",
        "\n",
        "def _conv_bn_relu(**conv_params):\n",
        "    \"\"\"Helper to build a conv -> BN -> relu block\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(input)\n",
        "        return _bn_relu(conv)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _bn_relu_conv(**conv_params):\n",
        "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
        "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        activation = _bn_relu(input)\n",
        "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(activation)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _shortcut(input, residual):\n",
        "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
        "    \"\"\"\n",
        "    # Expand channels of shortcut to match residual.\n",
        "    # Stride appropriately to match residual (width, height)\n",
        "    # Should be int if network architecture is correctly configured.\n",
        "    input_shape = K.int_shape(input)\n",
        "    residual_shape = K.int_shape(residual)\n",
        "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
        "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
        "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
        "\n",
        "    shortcut = input\n",
        "    # 1 X 1 conv if shape is different. Else identity.\n",
        "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
        "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=(stride_width, stride_height),\n",
        "                          padding=\"valid\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.0001))(input)\n",
        "\n",
        "    return add([shortcut, residual])\n",
        "\n",
        "\n",
        "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
        "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        for i in range(repetitions):\n",
        "            init_strides = (1, 1)\n",
        "            if i == 0 and not is_first_layer:\n",
        "                init_strides = (2, 2)\n",
        "            input = block_function(filters=filters, init_strides=init_strides,\n",
        "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
        "        return input\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
        "                           strides=init_strides,\n",
        "                           padding=\"same\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
        "                                  strides=init_strides)(input)\n",
        "\n",
        "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    Returns:\n",
        "        A final conv layer of filters * 4\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
        "                              strides=init_strides,\n",
        "                              padding=\"same\",\n",
        "                              kernel_initializer=\"he_normal\",\n",
        "                              kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
        "                                     strides=init_strides)(input)\n",
        "\n",
        "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
        "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _handle_dim_ordering():\n",
        "    global ROW_AXIS\n",
        "    global COL_AXIS\n",
        "    global CHANNEL_AXIS\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        ROW_AXIS = 1\n",
        "        COL_AXIS = 2\n",
        "        CHANNEL_AXIS = 3\n",
        "    else:\n",
        "        CHANNEL_AXIS = 1\n",
        "        ROW_AXIS = 2\n",
        "        COL_AXIS = 3\n",
        "\n",
        "\n",
        "def _get_block(identifier):\n",
        "    if isinstance(identifier, six.string_types):\n",
        "        res = globals().get(identifier)\n",
        "        if not res:\n",
        "            raise ValueError('Invalid {}'.format(identifier))\n",
        "        return res\n",
        "    return identifier\n",
        "\n",
        "\n",
        "class ResnetBuilder(object):\n",
        "    @staticmethod\n",
        "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
        "        \"\"\"Builds a custom ResNet like architecture.\n",
        "        Args:\n",
        "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
        "            num_outputs: The number of outputs at final softmax layer\n",
        "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
        "                The original paper used basic_block for layers < 50\n",
        "            repetitions: Number of repetitions of various block units.\n",
        "                At each block unit, the number of filters are doubled and the input size is halved\n",
        "        Returns:\n",
        "            The keras `Model`.\n",
        "        \"\"\"\n",
        "        _handle_dim_ordering()\n",
        "        if len(input_shape) != 3:\n",
        "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
        "\n",
        "        # Permute dimension order if necessary\n",
        "        if K.image_dim_ordering() == 'tf':\n",
        "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
        "\n",
        "        # Load function from str if needed.\n",
        "        block_fn = block_fn(block_fn)\n",
        "\n",
        "        input = Input(shape=input_shape)\n",
        "        conv1 = _conv_bn_relu(filters=64, kernel_size=(3, 3), strides=(2, 2),name='init-2d')(input)\n",
        "        #pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
        "        #x = Dropout(0.5)(pool1)\n",
        "        block = conv1\n",
        "        filters = 64\n",
        "        for i, r in enumerate(repetitions):\n",
        "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
        "            filters *= 2\n",
        "\n",
        "        # Last activation\n",
        "        block = _bn_relu(block)\n",
        "\n",
        "        # Classifier block\n",
        "        #block_shape = K.int_shape(block)\n",
        "        #pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
        "        #                         strides=(1, 1))(block)\n",
        "        #flatten1 = Flatten()(pool2)\n",
        "        #x = Dropout(0.5)(flatten1)\n",
        "        #dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
        "        #              activation=\"softmax\")(x)\n",
        "        x = Conv2D(200, (1,1), strides=(1,1), padding='same', name='final2d', use_bias=False)(block)\n",
        "        x = _bn_relu(x)\n",
        "        x = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
        "        # out = Flatten()(x)\n",
        "        out = Activation('softmax') (x)\n",
        "        model = Model(inputs=input, outputs=out)\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_18(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_34(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_50(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_101(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_152(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RRhQHa864adF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wnzu2sLmx7Az",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nb_classes = 200\n",
        "#nb_epoch = 100\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 32, 32\n",
        "img_channels = 3\n",
        "model = ResnetBuilder.build_resnet_50((img_channels, img_rows, img_cols), nb_classes)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JmByD_YOZDss",
        "colab_type": "code",
        "outputId": "3ae9549e-9afb-47b8-b59a-50149f8504af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plot_model(model, to_file='./tiny-imagenet-200/model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "items = os.listdir('./tiny-imagenet-200')\n",
        "print (items)    \n",
        "image = cv2.imread('./tiny-imagenet-200/model_plot.png')\n",
        "image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "plt.figure()\n",
        "plt.imshow(image)\n",
        "plt.colorbar()\n",
        "plt.grid(False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['train', 'model_plot.png', 'words.txt', 'val', 'wnids.txt', 'test']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAAFOCAYAAABdfFVPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDEGYQBiCMIEwBPl/d3XzKGAit1QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "on2zXDUMyC8Z",
        "colab_type": "code",
        "outputId": "97a74f28-84ae-4b3b-8b20-19356d9a1f87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6290
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 64)   1792        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 16, 16, 64)   256         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 64)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 64)   4160        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 16, 16, 64)   256         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 64)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 64)   36928       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 64)   256         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 64)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 256)  16640       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 256)  16640       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 16, 16, 256)  0           conv2d_58[0][0]                  \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 256)  1024        add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 256)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 64)   16448       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 64)   256         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 64)   0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 64)   36928       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 64)   256         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 64)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 256)  16640       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 16, 16, 256)  0           add_17[0][0]                     \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 256)  1024        add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 256)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 64)   16448       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 64)   256         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 64)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 64)   36928       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 64)   256         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 64)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 256)  16640       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 16, 16, 256)  0           add_18[0][0]                     \n",
            "                                                                 conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 256)  1024        add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 256)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 8, 8, 128)    32896       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 8, 8, 128)    512         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 8, 8, 128)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 8, 8, 128)    147584      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 8, 8, 128)    512         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 8, 8, 128)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 512)    131584      add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 8, 8, 512)    66048       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 8, 8, 512)    0           conv2d_68[0][0]                  \n",
            "                                                                 conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 8, 8, 512)    2048        add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 8, 8, 512)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 128)    65664       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 8, 8, 128)    512         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 8, 8, 128)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 128)    147584      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 8, 8, 128)    512         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 8, 8, 128)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 512)    66048       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 8, 8, 512)    0           add_20[0][0]                     \n",
            "                                                                 conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 512)    2048        add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 8, 8, 512)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 128)    65664       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 128)    512         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 128)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 128)    147584      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 128)    512         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 128)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 512)    66048       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 8, 8, 512)    0           add_21[0][0]                     \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 512)    2048        add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 512)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 128)    65664       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 128)    512         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 128)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 128)    147584      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 128)    512         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 128)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 512)    66048       activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 8, 8, 512)    0           add_22[0][0]                     \n",
            "                                                                 conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 8, 8, 512)    2048        add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 512)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 4, 4, 256)    131328      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 4, 4, 256)    1024        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 4, 4, 256)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 4, 4, 256)    590080      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 4, 4, 256)    1024        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 4, 4, 256)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 4, 4, 1024)   525312      add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 4, 4, 1024)   263168      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 4, 4, 1024)   0           conv2d_81[0][0]                  \n",
            "                                                                 conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 4, 4, 1024)   4096        add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 4, 4, 256)    262400      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 4, 4, 256)    1024        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 4, 4, 256)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 4, 4, 256)    590080      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 4, 4, 256)    1024        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 4, 4, 256)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 4, 4, 1024)   263168      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 4, 4, 1024)   0           add_24[0][0]                     \n",
            "                                                                 conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 4, 4, 1024)   4096        add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 4, 4, 256)    262400      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 4, 4, 256)    1024        conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 4, 4, 256)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 4, 4, 256)    590080      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 4, 4, 256)    1024        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 4, 4, 256)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 4, 4, 1024)   263168      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 4, 4, 1024)   0           add_25[0][0]                     \n",
            "                                                                 conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 4, 4, 1024)   4096        add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 4, 4, 256)    262400      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 4, 4, 256)    1024        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 4, 4, 256)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 4, 4, 256)    590080      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 4, 4, 256)    1024        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 4, 4, 256)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 4, 4, 1024)   263168      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 4, 4, 1024)   0           add_26[0][0]                     \n",
            "                                                                 conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 4, 4, 1024)   4096        add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 4, 4, 256)    262400      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 4, 4, 256)    1024        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 4, 4, 256)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 4, 4, 256)    590080      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 4, 4, 256)    1024        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 4, 4, 256)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 4, 4, 1024)   263168      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 4, 4, 1024)   0           add_27[0][0]                     \n",
            "                                                                 conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 4, 4, 1024)   4096        add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 4, 4, 256)    262400      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 4, 4, 256)    1024        conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 4, 4, 256)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 4, 4, 256)    590080      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 4, 4, 256)    1024        conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 4, 4, 256)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 4, 4, 1024)   263168      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 4, 4, 1024)   0           add_28[0][0]                     \n",
            "                                                                 conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 4, 4, 1024)   4096        add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 2, 2, 512)    524800      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 2, 2, 512)    2048        conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 2, 2, 512)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 2, 2, 512)    2359808     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 2, 2, 512)    2048        conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 2, 2, 512)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 2, 2, 2048)   2099200     add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 2, 2, 2048)   0           conv2d_100[0][0]                 \n",
            "                                                                 conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 2, 2, 2048)   8192        add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 2, 2, 2048)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 2, 2, 512)    1049088     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 2, 2, 512)    2048        conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 2, 2, 512)    0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 2, 2, 512)    2359808     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 2, 2, 512)    2048        conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 2, 2, 512)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 2, 2, 2048)   0           add_30[0][0]                     \n",
            "                                                                 conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 2, 2, 2048)   8192        add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 2, 2, 2048)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 2, 2, 512)    1049088     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 2, 2, 512)    2048        conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 2, 2, 512)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 2, 2, 512)    2359808     activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 2, 2, 512)    2048        conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 2, 2, 512)    0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 2, 2, 2048)   0           add_31[0][0]                     \n",
            "                                                                 conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 2, 2, 2048)   8192        add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 2, 2, 2048)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "final2d (Conv2D)                (None, 2, 2, 200)    409600      activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 2, 2, 200)    800         final2d[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 2, 2, 200)    0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 200)          0           activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 200)          0           global_average_pooling2d_2[0][0] \n",
            "==================================================================================================\n",
            "Total params: 23,975,072\n",
            "Trainable params: 23,929,232\n",
            "Non-trainable params: 45,840\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8V-LArlmyFyX",
        "colab_type": "code",
        "outputId": "44e30b9b-3062-42d5-869c-638ee8bc2231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1785
        }
      },
      "cell_type": "code",
      "source": [
        "#model.fit_generator(train_generator, epochs=nb_epoch, steps_per_epoch=200, validation_steps=200, validation_data=validation_generator\n",
        "##steps_per_epoch=Integer. Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. \n",
        "#It should typically be equal to ceil(num_samples / batch_size) Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.\n",
        "##validation_steps=Only relevant if validation_data is a generator. Total number of steps (batches of samples) to yield from validation_data generator before stopping at the end of every epoch. \n",
        "#It should typically be equal to the number of samples of your validation dataset divided by the batch size. Optional for Sequence: if unspecified, will use the len(validation_data) as a number of steps.\n",
        "##epochs: Integer. Number of epochs to train the model. An epoch is an iteration over the entire data provided, as defined by steps_per_epoch. \n",
        "#Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs,\n",
        "#but merely until the epoch of index epochs is reached.\n",
        "#steps_per_epoch=100000/200=500\n",
        "#validation_steps=10000/200=50\n",
        "#nb_epoch = 100\n",
        "nb_epoch = 50\n",
        "model.fit_generator(train_generator, epochs=nb_epoch, steps_per_epoch=500, validation_steps=50, validation_data=validation_generator)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/50\n",
            "500/500 [==============================] - 324s 647ms/step - loss: 6.7907 - acc: 0.0656 - val_loss: 6.2086 - val_acc: 0.0466\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 289s 577ms/step - loss: 4.9995 - acc: 0.1088 - val_loss: 5.1426 - val_acc: 0.0714\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 290s 580ms/step - loss: 4.6614 - acc: 0.1293 - val_loss: 5.0695 - val_acc: 0.0785\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 288s 576ms/step - loss: 4.4718 - acc: 0.1497 - val_loss: 4.9462 - val_acc: 0.0889\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 289s 577ms/step - loss: 4.3442 - acc: 0.1637 - val_loss: 4.9587 - val_acc: 0.1118\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 288s 576ms/step - loss: 4.2359 - acc: 0.1777 - val_loss: 4.8520 - val_acc: 0.1125\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 289s 577ms/step - loss: 4.1440 - acc: 0.1899 - val_loss: 4.4483 - val_acc: 0.1473\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 288s 576ms/step - loss: 4.0599 - acc: 0.2032 - val_loss: 4.2760 - val_acc: 0.1799\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 287s 575ms/step - loss: 3.9939 - acc: 0.2114 - val_loss: 4.5054 - val_acc: 0.1459\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 289s 579ms/step - loss: 3.9195 - acc: 0.2252 - val_loss: 4.4022 - val_acc: 0.1642\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 288s 577ms/step - loss: 3.8611 - acc: 0.2357 - val_loss: 4.2469 - val_acc: 0.1809\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 288s 576ms/step - loss: 3.8013 - acc: 0.2430 - val_loss: 3.9937 - val_acc: 0.2093\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 289s 579ms/step - loss: 3.7535 - acc: 0.2526 - val_loss: 4.1212 - val_acc: 0.2048\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 289s 578ms/step - loss: 3.7044 - acc: 0.2589 - val_loss: 3.9925 - val_acc: 0.2245\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 289s 578ms/step - loss: 3.6643 - acc: 0.2675 - val_loss: 4.6776 - val_acc: 0.1591\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 288s 576ms/step - loss: 3.6168 - acc: 0.2741 - val_loss: 4.0950 - val_acc: 0.2085\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 289s 577ms/step - loss: 3.5859 - acc: 0.2813 - val_loss: 3.8773 - val_acc: 0.2399\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 289s 579ms/step - loss: 3.5521 - acc: 0.2866 - val_loss: 4.2185 - val_acc: 0.2054\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 289s 577ms/step - loss: 3.5191 - acc: 0.2930 - val_loss: 3.8492 - val_acc: 0.2475\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 289s 577ms/step - loss: 3.4875 - acc: 0.2994 - val_loss: 4.1391 - val_acc: 0.2069\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 289s 578ms/step - loss: 3.4583 - acc: 0.3050 - val_loss: 3.7727 - val_acc: 0.2748\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 289s 578ms/step - loss: 3.4305 - acc: 0.3095 - val_loss: 4.2707 - val_acc: 0.2069\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 288s 576ms/step - loss: 3.4092 - acc: 0.3149 - val_loss: 4.0612 - val_acc: 0.2374\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 289s 578ms/step - loss: 3.3811 - acc: 0.3196 - val_loss: 3.9108 - val_acc: 0.2546\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 289s 578ms/step - loss: 3.3673 - acc: 0.3233 - val_loss: 3.9789 - val_acc: 0.2465\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 286s 573ms/step - loss: 3.3407 - acc: 0.3289 - val_loss: 4.0300 - val_acc: 0.2380\n",
            "Epoch 27/50\n",
            "500/500 [==============================] - 286s 573ms/step - loss: 3.3191 - acc: 0.3318 - val_loss: 3.7987 - val_acc: 0.2746\n",
            "Epoch 28/50\n",
            "500/500 [==============================] - 285s 570ms/step - loss: 3.2980 - acc: 0.3362 - val_loss: 3.8676 - val_acc: 0.2654\n",
            "Epoch 29/50\n",
            "500/500 [==============================] - 286s 571ms/step - loss: 3.2781 - acc: 0.3407 - val_loss: 4.0973 - val_acc: 0.2364\n",
            "Epoch 30/50\n",
            "500/500 [==============================] - 291s 583ms/step - loss: 3.2565 - acc: 0.3449 - val_loss: 3.8830 - val_acc: 0.2552\n",
            "Epoch 31/50\n",
            "500/500 [==============================] - 289s 578ms/step - loss: 3.2454 - acc: 0.3465 - val_loss: 4.3110 - val_acc: 0.2121\n",
            "Epoch 32/50\n",
            "500/500 [==============================] - 288s 576ms/step - loss: 3.2204 - acc: 0.3510 - val_loss: 4.0299 - val_acc: 0.2519\n",
            "Epoch 33/50\n",
            "500/500 [==============================] - 289s 578ms/step - loss: 3.2125 - acc: 0.3539 - val_loss: 4.0477 - val_acc: 0.2401\n",
            "Epoch 34/50\n",
            "500/500 [==============================] - 290s 579ms/step - loss: 3.1954 - acc: 0.3589 - val_loss: 4.4702 - val_acc: 0.2125\n",
            "Epoch 35/50\n",
            "500/500 [==============================] - 288s 576ms/step - loss: 3.1805 - acc: 0.3597 - val_loss: 4.2662 - val_acc: 0.2275\n",
            "Epoch 36/50\n",
            "500/500 [==============================] - 289s 578ms/step - loss: 3.1610 - acc: 0.3653 - val_loss: 4.2124 - val_acc: 0.2334\n",
            "Epoch 37/50\n",
            "500/500 [==============================] - 287s 575ms/step - loss: 3.1481 - acc: 0.3687 - val_loss: 3.8428 - val_acc: 0.2763\n",
            "Epoch 38/50\n",
            "500/500 [==============================] - 288s 577ms/step - loss: 3.1319 - acc: 0.3703 - val_loss: 3.6455 - val_acc: 0.2939\n",
            "Epoch 39/50\n",
            "500/500 [==============================] - 290s 579ms/step - loss: 3.1173 - acc: 0.3738 - val_loss: 3.7890 - val_acc: 0.2861\n",
            "Epoch 40/50\n",
            "500/500 [==============================] - 290s 579ms/step - loss: 3.1095 - acc: 0.3760 - val_loss: 4.0231 - val_acc: 0.2616\n",
            "Epoch 41/50\n",
            "500/500 [==============================] - 288s 576ms/step - loss: 3.0959 - acc: 0.3796 - val_loss: 3.6584 - val_acc: 0.3131\n",
            "Epoch 42/50\n",
            "500/500 [==============================] - 288s 577ms/step - loss: 3.0863 - acc: 0.3820 - val_loss: 4.0120 - val_acc: 0.2674\n",
            "Epoch 43/50\n",
            "500/500 [==============================] - 289s 578ms/step - loss: 3.0736 - acc: 0.3851 - val_loss: 3.7617 - val_acc: 0.2891\n",
            "Epoch 44/50\n",
            "500/500 [==============================] - 290s 580ms/step - loss: 3.0557 - acc: 0.3877 - val_loss: 4.0412 - val_acc: 0.2587\n",
            "Epoch 45/50\n",
            "500/500 [==============================] - 287s 575ms/step - loss: 3.0454 - acc: 0.3896 - val_loss: 4.2525 - val_acc: 0.2439\n",
            "Epoch 46/50\n",
            "500/500 [==============================] - 288s 575ms/step - loss: 3.0377 - acc: 0.3931 - val_loss: 4.4584 - val_acc: 0.2420\n",
            "Epoch 47/50\n",
            "500/500 [==============================] - 287s 574ms/step - loss: 3.0267 - acc: 0.3943 - val_loss: 4.3316 - val_acc: 0.2382\n",
            "Epoch 48/50\n",
            "500/500 [==============================] - 287s 574ms/step - loss: 3.0067 - acc: 0.3987 - val_loss: 4.3988 - val_acc: 0.2374\n",
            "Epoch 49/50\n",
            "500/500 [==============================] - 287s 573ms/step - loss: 3.0005 - acc: 0.3996 - val_loss: 3.9882 - val_acc: 0.2874\n",
            "Epoch 50/50\n",
            "500/500 [==============================] - 287s 575ms/step - loss: 2.9931 - acc: 0.4021 - val_loss: 3.7858 - val_acc: 0.2999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f44ebb2a4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "MJ8bXsbg1eao",
        "colab_type": "code",
        "outputId": "80b7a8de-66d5-4950-fcd8-76f11809b5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "#score = model.evaluate(x_test\n",
        ", y_test, verbose=1)\n",
        "#print('Test loss:', score[0])\n",
        "model_yaml = model.to_yaml()\n",
        "with open(\"session4_vkt_model240319.yaml\", \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "#print('Test accuracy:', score[1])\n",
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"session4_vkt_model240319.h5\")\n",
        "print(\"Saved the model to disk\")\n",
        "!ls\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved the model to disk\n",
            "model.h5    session4_vkt_model240319.h5    tiny-imagenet-200\n",
            "model.yaml  session4_vkt_model240319.yaml  tiny-imagenet-200.zip\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V6Ol6jdO-Dha",
        "colab_type": "code",
        "outputId": "8a4f4f22-fd02-4abc-b6fc-35f0df2b26c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6307
        }
      },
      "cell_type": "code",
      "source": [
        "# load YAML and create model\n",
        "yaml_file = open('session4_vkt_model240319.yaml', 'r')\n",
        "loaded_model_yaml = yaml_file.read()\n",
        "yaml_file.close()\n",
        "##load from file\n",
        "newmodel = model_from_yaml(loaded_model_yaml)\n",
        "# load weights into new model\n",
        "newmodel.load_weights(\"session4_vkt_model240319.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "newmodel.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "newmodel.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 64)   1792        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 16, 16, 64)   256         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 64)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 64)   4160        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 16, 16, 64)   256         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 64)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 64)   36928       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 64)   256         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 64)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 256)  16640       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 256)  16640       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 16, 16, 256)  0           conv2d_58[0][0]                  \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 256)  1024        add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 256)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 64)   16448       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 64)   256         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 64)   0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 64)   36928       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 64)   256         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 64)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 256)  16640       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 16, 16, 256)  0           add_17[0][0]                     \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 256)  1024        add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 256)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 64)   16448       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 64)   256         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 64)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 64)   36928       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 64)   256         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 64)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 256)  16640       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 16, 16, 256)  0           add_18[0][0]                     \n",
            "                                                                 conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 256)  1024        add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 256)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 8, 8, 128)    32896       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 8, 8, 128)    512         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 8, 8, 128)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 8, 8, 128)    147584      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 8, 8, 128)    512         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 8, 8, 128)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 512)    131584      add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 8, 8, 512)    66048       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 8, 8, 512)    0           conv2d_68[0][0]                  \n",
            "                                                                 conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 8, 8, 512)    2048        add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 8, 8, 512)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 128)    65664       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 8, 8, 128)    512         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 8, 8, 128)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 128)    147584      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 8, 8, 128)    512         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 8, 8, 128)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 512)    66048       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 8, 8, 512)    0           add_20[0][0]                     \n",
            "                                                                 conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 512)    2048        add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 8, 8, 512)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 128)    65664       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 128)    512         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 128)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 128)    147584      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 128)    512         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 128)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 512)    66048       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 8, 8, 512)    0           add_21[0][0]                     \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 512)    2048        add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 512)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 128)    65664       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 128)    512         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 128)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 128)    147584      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 128)    512         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 128)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 512)    66048       activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 8, 8, 512)    0           add_22[0][0]                     \n",
            "                                                                 conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 8, 8, 512)    2048        add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 512)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 4, 4, 256)    131328      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 4, 4, 256)    1024        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 4, 4, 256)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 4, 4, 256)    590080      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 4, 4, 256)    1024        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 4, 4, 256)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 4, 4, 1024)   525312      add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 4, 4, 1024)   263168      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 4, 4, 1024)   0           conv2d_81[0][0]                  \n",
            "                                                                 conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 4, 4, 1024)   4096        add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 4, 4, 256)    262400      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 4, 4, 256)    1024        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 4, 4, 256)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 4, 4, 256)    590080      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 4, 4, 256)    1024        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 4, 4, 256)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 4, 4, 1024)   263168      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 4, 4, 1024)   0           add_24[0][0]                     \n",
            "                                                                 conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 4, 4, 1024)   4096        add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 4, 4, 256)    262400      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 4, 4, 256)    1024        conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 4, 4, 256)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 4, 4, 256)    590080      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 4, 4, 256)    1024        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 4, 4, 256)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 4, 4, 1024)   263168      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 4, 4, 1024)   0           add_25[0][0]                     \n",
            "                                                                 conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 4, 4, 1024)   4096        add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 4, 4, 256)    262400      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 4, 4, 256)    1024        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 4, 4, 256)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 4, 4, 256)    590080      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 4, 4, 256)    1024        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 4, 4, 256)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 4, 4, 1024)   263168      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 4, 4, 1024)   0           add_26[0][0]                     \n",
            "                                                                 conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 4, 4, 1024)   4096        add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 4, 4, 256)    262400      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 4, 4, 256)    1024        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 4, 4, 256)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 4, 4, 256)    590080      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 4, 4, 256)    1024        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 4, 4, 256)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 4, 4, 1024)   263168      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 4, 4, 1024)   0           add_27[0][0]                     \n",
            "                                                                 conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 4, 4, 1024)   4096        add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 4, 4, 256)    262400      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 4, 4, 256)    1024        conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 4, 4, 256)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 4, 4, 256)    590080      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 4, 4, 256)    1024        conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 4, 4, 256)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 4, 4, 1024)   263168      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 4, 4, 1024)   0           add_28[0][0]                     \n",
            "                                                                 conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 4, 4, 1024)   4096        add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 2, 2, 512)    524800      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 2, 2, 512)    2048        conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 2, 2, 512)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 2, 2, 512)    2359808     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 2, 2, 512)    2048        conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 2, 2, 512)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 2, 2, 2048)   2099200     add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 2, 2, 2048)   0           conv2d_100[0][0]                 \n",
            "                                                                 conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 2, 2, 2048)   8192        add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 2, 2, 2048)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 2, 2, 512)    1049088     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 2, 2, 512)    2048        conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 2, 2, 512)    0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 2, 2, 512)    2359808     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 2, 2, 512)    2048        conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 2, 2, 512)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 2, 2, 2048)   0           add_30[0][0]                     \n",
            "                                                                 conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 2, 2, 2048)   8192        add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 2, 2, 2048)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 2, 2, 512)    1049088     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 2, 2, 512)    2048        conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 2, 2, 512)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 2, 2, 512)    2359808     activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 2, 2, 512)    2048        conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 2, 2, 512)    0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 2, 2, 2048)   0           add_31[0][0]                     \n",
            "                                                                 conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 2, 2, 2048)   8192        add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 2, 2, 2048)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "final2d (Conv2D)                (None, 2, 2, 200)    409600      activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 2, 2, 200)    800         final2d[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 2, 2, 200)    0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 200)          0           activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 200)          0           global_average_pooling2d_2[0][0] \n",
            "==================================================================================================\n",
            "Total params: 23,975,072\n",
            "Trainable params: 23,929,232\n",
            "Non-trainable params: 45,840\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fa9P-nar5gD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "16ec0e1d-5038-465d-b4af-c6aac8389c1d"
      },
      "cell_type": "code",
      "source": [
        "nb_epoch = 1\n",
        "newmodel.fit_generator(train_generator, epochs=nb_epoch, steps_per_epoch=500, validation_steps=50, validation_data=validation_generator)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "500/500 [==============================] - 317s 633ms/step - loss: 2.9839 - acc: 0.4043 - val_loss: 3.8416 - val_acc: 0.2874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f44ebb2ada0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}