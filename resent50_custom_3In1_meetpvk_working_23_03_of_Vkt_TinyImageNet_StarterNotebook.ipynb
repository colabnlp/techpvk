{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resent50_custom_3In1_meetpvk_working_23_03_of Vkt_TinyImageNet_StarterNotebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/techpvk/techpvk/blob/master/resent50_custom_3In1_meetpvk_working_23_03_of_Vkt_TinyImageNet_StarterNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "I4th9KTGttp2",
        "colab_type": "code",
        "outputId": "d173b312-9ea7-41a0-f210-e21da6f18cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# List and Clear the Data first\n",
        "!ls\n",
        "#!rm -rf sample_data tiny-imagenet-200\ttiny-imagenet-200.zip\n",
        "# list content after the clearing data\n",
        "#!ls\n",
        "# Download the file\n",
        "#!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "  #unzip and list\n",
        "#!unzip -qq 'tiny-imagenet-200.zip'\n",
        "#!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tiny-imagenet-200  tiny-imagenet-200.zip  weights.best.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7l_PCFURg9x_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import the required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import six\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from __future__ import division\n",
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Activation,\n",
        "    Dense,\n",
        "    Flatten,\n",
        "    Dropout,\n",
        "    SeparableConv2D\n",
        ")\n",
        "from keras.layers.convolutional import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    AveragePooling2D\n",
        ")\n",
        "from keras.layers.merge import add\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.models import Model, load_model, model_from_yaml\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pfHaHidXMWM3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _bn_relu(input):\n",
        "    \"\"\"Helper to build a BN -> relu block\n",
        "    \"\"\"\n",
        "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
        "    return Activation(\"relu\")(norm)\n",
        "\n",
        "\n",
        "def _conv_bn_relu(**conv_params):\n",
        "    \"\"\"Helper to build a conv -> BN -> relu block\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    name = conv_params[\"name\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "    def f(input):\n",
        "        conv = SeparableConv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer,\n",
        "                     name=name)(input)\n",
        "        return _bn_relu(conv)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _bn_relu_conv(**conv_params):\n",
        "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
        "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "    def f(input):\n",
        "        activation = _bn_relu(input)\n",
        "        return SeparableConv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(activation)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _shortcut(input, residual):\n",
        "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
        "    \"\"\"\n",
        "    # Expand channels of shortcut to match residual.\n",
        "    # Stride appropriately to match residual (width, height)\n",
        "    # Should be int if network architecture is correctly configured.\n",
        "    input_shape = K.int_shape(input)\n",
        "    residual_shape = K.int_shape(residual)\n",
        "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
        "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
        "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
        "\n",
        "    shortcut = input\n",
        "    # 1 X 1 conv if shape is different. Else identity.\n",
        "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
        "        shortcut = SeparableConv2D(filters=residual_shape[CHANNEL_AXIS],\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=(stride_width, stride_height),\n",
        "                          padding=\"valid\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.0001))(input)\n",
        "    return add([shortcut, residual])\n",
        "\n",
        "\n",
        "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
        "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        \n",
        "        for i in range(repetitions):\n",
        "            init_strides = (1, 1)\n",
        "            if i == 0 and not is_first_layer:\n",
        "                init_strides = (2, 2)\n",
        "            input = block_function(filters=filters, init_strides=init_strides,\n",
        "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
        "        return input\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
        "                           strides=init_strides,\n",
        "                           padding=\"same\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
        "                                  strides=init_strides)(input)\n",
        "\n",
        "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    Returns:\n",
        "        A final conv layer of filters * 4\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
        "                              strides=init_strides,\n",
        "                              padding=\"same\",\n",
        "                              kernel_initializer=\"he_normal\",\n",
        "                              kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
        "                                     strides=init_strides)(input)\n",
        "\n",
        "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
        "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "def bottleneck_pyramid(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    Returns:\n",
        "        A final conv layer of filters * 4\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv_1_1 = SeparableConv2D(filters=filters, kernel_size=(1, 1),\n",
        "                              strides=init_strides,\n",
        "                              padding=\"same\",\n",
        "                              kernel_initializer=\"he_normal\",\n",
        "                              kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
        "                                     strides=(1,1))(input)\n",
        "\n",
        "        conv_3_3_1 = _bn_relu_conv(filters=filters * 2, kernel_size=(3, 3))(conv_1_1)\n",
        "        conv_3_3_2 = _bn_relu_conv(filters=filters * 4, kernel_size=(3, 3))(conv_3_3_1)\n",
        "        conv_3_3_3 = _bn_relu_conv(filters=filters * 8, kernel_size=(3, 3))(conv_3_3_2)\n",
        "        if is_first_block_of_first_layer:\n",
        "           return _shortcut(input, conv_3_3_3)\n",
        "        else:\n",
        "            conv_3_3_3 = _bn_relu(conv_3_3_3)\n",
        "            conv_max_pool = MaxPooling2D(pool_size=(2, 2))(conv_3_3_3)\n",
        "            residual = _bn_relu(conv_max_pool)\n",
        "            #residual = _bn_relu_conv(filters=filters * 8, kernel_size=(3, 3))(conv_3_3_2)\n",
        "            return _shortcut(input, residual)\n",
        "          \n",
        "    return f\n",
        "\n",
        "\n",
        "def _handle_dim_ordering():\n",
        "    global ROW_AXIS\n",
        "    global COL_AXIS\n",
        "    global CHANNEL_AXIS\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        ROW_AXIS = 1\n",
        "        COL_AXIS = 2\n",
        "        CHANNEL_AXIS = 3\n",
        "    else:\n",
        "        CHANNEL_AXIS = 1\n",
        "        ROW_AXIS = 2\n",
        "        COL_AXIS = 3\n",
        "\n",
        "\n",
        "def _get_block(identifier):\n",
        "    if isinstance(identifier, six.string_types):\n",
        "        res = globals().get(identifier)\n",
        "        if not res:\n",
        "            raise ValueError('Invalid {}'.format(identifier))\n",
        "        return res\n",
        "    return identifier\n",
        "\n",
        "\n",
        "class ResnetBuilder(object):\n",
        "    @staticmethod\n",
        "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
        "        \"\"\"Builds a custom ResNet like architecture.\n",
        "        Args:\n",
        "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
        "            num_outputs: The number of outputs at final softmax layer\n",
        "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
        "                The original paper used basic_block for layers < 50\n",
        "            repetitions: Number of repetitions of various block units.\n",
        "                At each block unit, the number of filters are doubled and the input size is halved\n",
        "        Returns:\n",
        "            The keras `Model`.\n",
        "        \"\"\"\n",
        "        _handle_dim_ordering()\n",
        "        if len(input_shape) != 3:\n",
        "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
        "\n",
        "        # Permute dimension order if necessary\n",
        "        if K.image_dim_ordering() == 'tf':\n",
        "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
        "        # Load function from str if needed.\n",
        "        block_fn = _get_block(block_fn)\n",
        "        input = Input(shape=input_shape)\n",
        "        conv1 = _conv_bn_relu(filters=64, kernel_size=(3, 3), strides=(1, 1),name='init-2d')(input)\n",
        "        #pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
        "        #x = Dropout(0.5)(pool1)\n",
        "        #block = conv1\n",
        "        block = input\n",
        "        filters = 32\n",
        "        for i, r in enumerate(repetitions):\n",
        "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
        "            filters *= 2\n",
        "\n",
        "        # Last activation\n",
        "        block = _bn_relu(block)\n",
        "\n",
        "        # Classifier block\n",
        "        #block_shape = K.int_shape(block)\n",
        "        #pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
        "        #                         strides=(1, 1))(block)\n",
        "        #flatten1 = Flatten()(pool2)\n",
        "        #x = Dropout(0.5)(flatten1)\n",
        "        #dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
        "        #              activation=\"softmax\")(x)\n",
        "        x = Conv2D(200, (1,1), strides=(1,1), padding='same', name='final2d', use_bias=False)(block)\n",
        "        x = _bn_relu(x)\n",
        "        x = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
        "        # out = Flatten()(x)\n",
        "        out = Activation('softmax') (x)\n",
        "        model = Model(inputs=input, outputs=out)\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_18(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_34(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_50(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
        "      \n",
        "    @staticmethod\n",
        "    def build_resnet_50_pyramid(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck_pyramid, [1, 1, 1, 1])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_101(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_152(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r7SjAhI2Jskn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wRYLyZtwKKDp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "#val_data.head(10)\n",
        "# Use Augmentaion parameters as required.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        "    )\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(32, 32), color_mode='rgb', \n",
        "                                                    batch_size=200, class_mode='categorical', shuffle=True, seed=42)\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(32, 32),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=200, shuffle=True, seed=42)\n",
        "x_batch, y_batch = next(train_generator)\n",
        "x_batch.shape\n",
        "# Plot Generator images.  ** Re-run the cell to view different set of images.\n",
        "\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "\n",
        "for i in range(8):\n",
        "    sub = fig.add_subplot(2, 4, i + 1)\n",
        "    sub.imshow(x_batch[i,:,:], interpolation='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wnzu2sLmx7Az",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nb_classes = 200\n",
        "#nb_epoch = 100\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 32, 32\n",
        "img_channels = 3\n",
        "model = ResnetBuilder.build_resnet_50_pyramid((img_channels,img_rows,img_cols), nb_classes)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JmByD_YOZDss",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='./tiny-imagenet-200/model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "from google.colab import files\n",
        "\n",
        "files.download('./tiny-imagenet-200/model_plot.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "on2zXDUMyC8Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "#model.fit_generator(train_generator, epochs=nb_epoch, steps_per_epoch=200, validation_steps=200, validation_data=validation_generator\n",
        "##steps_per_epoch=Integer. Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. \n",
        "#It should typically be equal to ceil(num_samples / batch_size) Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.\n",
        "##validation_steps=Only relevant if validation_data is a generator. Total number of steps (batches of samples) to yield from validation_data generator before stopping at the end of every epoch. \n",
        "#It should typically be equal to the number of samples of your validation dataset divided by the batch size. Optional for Sequence: if unspecified, will use the len(validation_data) as a number of steps.\n",
        "##epochs: Integer. Number of epochs to train the model. An epoch is an iteration over the entire data provided, as defined by steps_per_epoch. \n",
        "#Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs,\n",
        "#but merely until the epoch of index epochs is reached.\n",
        "#steps_per_epoch=100000/200=500\n",
        "#validation_steps=10000/200=50\n",
        "#nb_epoch = 100\n",
        "# checkpoint\n",
        "filepath=\"./tiny-imagenet-200/weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "nb_epoch = 20\n",
        "model.fit_generator(train_generator, epochs=nb_epoch, steps_per_epoch=500, validation_steps=50, validation_data=validation_generator, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8V-LArlmyFyX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 16, 16\n",
        "batch_size=400\n",
        "#val_data.head(10)\n",
        "# Use Augmentaion parameters as required.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255\n",
        "    )\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_rows, img_cols), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_rows, img_cols),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)\n",
        "x_batch, y_batch = next(train_generator)\n",
        "x_batch.shape\n",
        "# Plot Generator images.  ** Re-run the cell to view different set of images.\n",
        "\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "\n",
        "for i in range(8):\n",
        "    sub = fig.add_subplot(2, 4, i + 1)\n",
        "    sub.imshow(x_batch[i,:,:], interpolation='nearest')\n",
        "nb_classes = 200\n",
        "#nb_epoch = 100\n",
        "img_channels = 3\n",
        "model = ResnetBuilder.build_resnet_50_pyramid((img_channels,img_rows,img_cols), nb_classes)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "#model.summary()\n",
        "\n",
        "#model.fit_generator(train_generator, epochs=nb_epoch, steps_per_epoch=200, validation_steps=200, validation_data=validation_generator\n",
        "##steps_per_epoch=Integer. Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. \n",
        "#It should typically be equal to ceil(num_samples / batch_size) Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.\n",
        "##validation_steps=Only relevant if validation_data is a generator. Total number of steps (batches of samples) to yield from validation_data generator before stopping at the end of every epoch. \n",
        "#It should typically be equal to the number of samples of your validation dataset divided by the batch size. Optional for Sequence: if unspecified, will use the len(validation_data) as a number of steps.\n",
        "##epochs: Integer. Number of epochs to train the model. An epoch is an iteration over the entire data provided, as defined by steps_per_epoch. \n",
        "#Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs,\n",
        "#but merely until the epoch of index epochs is reached.\n",
        "#steps_per_epoch=100000/200=500\n",
        "#validation_steps=10000/200=50\n",
        "#nb_epoch = 100\n",
        "# checkpoint\n",
        "filepath=\"./tiny-imagenet-200/weights.best.hdf5\"\n",
        "model.load_weights(filepath)\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "nb_epoch = 5\n",
        "model.fit_generator(train_generator, epochs=nb_epoch, steps_per_epoch=500, validation_steps=50, validation_data=validation_generator, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MJ8bXsbg1eao",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 64, 64\n",
        "batch_size=50\n",
        "#val_data.head(10)\n",
        "# Use Augmentaion parameters as required.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        "    )\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_rows, img_cols), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_rows, img_cols),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)\n",
        "x_batch, y_batch = next(train_generator)\n",
        "x_batch.shape\n",
        "# Plot Generator images.  ** Re-run the cell to view different set of images.\n",
        "\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "\n",
        "for i in range(8):\n",
        "    sub = fig.add_subplot(2, 4, i + 1)\n",
        "    sub.imshow(x_batch[i,:,:], interpolation='nearest')\n",
        "nb_classes = 200\n",
        "#nb_epoch = 100\n",
        "img_channels = 3\n",
        "model = ResnetBuilder.build_resnet_50_pyramid((img_channels,img_rows,img_cols), nb_classes)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "#model.summary()\n",
        "\n",
        "#model.fit_generator(train_generator, ep`ochs=nb_epoch, steps_per_epoch=200, validation_steps=200, validation_data=validation_generator\n",
        "##steps_per_epoch=Integer. Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. \n",
        "#It should typically be equal to ceil(num_samples / batch_size) Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.\n",
        "##validation_steps=Only relevant if validation_data is a generator. Total number of steps (batches of samples) to yield from validation_data generator before stopping at the end of every epoch. \n",
        "#It should typically be equal to the number of samples of your validation dataset divided by the batch size. Optional for Sequence: if unspecified, will use the len(validation_data) as a number of steps.\n",
        "##epochs: Integer. Number of epochs to train the model. An epoch is an iteration over the entire data provided, as defined by steps_per_epoch. \n",
        "#Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs,\n",
        "#but merely until the epoch of index epochs is reached.\n",
        "#steps_per_epoch=100000/200=500\n",
        "#validation_steps=10000/200=50\n",
        "#nb_epoch = 100\n",
        "# checkpoint\n",
        "filepath=\"./tiny-imagenet-200/weights.best.hdf5\"\n",
        "model.load_weights(filepath)\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "nb_epoch = 5\n",
        "model.fit_generator(train_generator, epochs=nb_epoch, steps_per_epoch=500, validation_steps=50, validation_data=validation_generator, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SrMXrDWc9j4A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 16, 16\n",
        "batch_size=400\n",
        "#val_data.head(10)\n",
        "# Use Augmentaion parameters as required.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255\n",
        "    )\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_rows, img_cols), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_rows, img_cols),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)\n",
        "x_batch, y_batch = next(train_generator)\n",
        "x_batch.shape\n",
        "# Plot Generator images.  ** Re-run the cell to view different set of images.\n",
        "\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "\n",
        "for i in range(8):\n",
        "    sub = fig.add_subplot(2, 4, i + 1)\n",
        "    sub.imshow(x_batch[i,:,:], interpolation='nearest')\n",
        "nb_classes = 200\n",
        "#nb_epoch = 100\n",
        "img_channels = 3\n",
        "model = ResnetBuilder.build_resnet_50_pyramid((img_channels,img_rows,img_cols), nb_classes)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "#model.summary()\n",
        "\n",
        "#model.fit_generator(train_generator, epochs=nb_epoch, steps_per_epoch=200, validation_steps=200, validation_data=validation_generator\n",
        "##steps_per_epoch=Integer. Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. \n",
        "#It should typically be equal to ceil(num_samples / batch_size) Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.\n",
        "##validation_steps=Only relevant if validation_data is a generator. Total number of steps (batches of samples) to yield from validation_data generator before stopping at the end of every epoch. \n",
        "#It should typically be equal to the number of samples of your validation dataset divided by the batch size. Optional for Sequence: if unspecified, will use the len(validation_data) as a number of steps.\n",
        "##epochs: Integer. Number of epochs to train the model. An epoch is an iteration over the entire data provided, as defined by steps_per_epoch. \n",
        "#Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs,\n",
        "#but merely until the epoch of index epochs is reached.\n",
        "#steps_per_epoch=100000/200=500\n",
        "#validation_steps=10000/200=50\n",
        "#nb_epoch = 100\n",
        "# checkpoint\n",
        "filepath=\"./tiny-imagenet-200/weights.best.hdf5\"\n",
        "model.load_weights(filepath)\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "nb_epoch = 5\n",
        "model.fit_generator(train_generator, epochs=nb_epoch, steps_per_epoch=500, validation_steps=50, validation_data=validation_generator, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wfQO2I4f9mzq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 64, 64\n",
        "batch_size=50\n",
        "#val_data.head(10)\n",
        "# Use Augmentaion parameters as required.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        "    )\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_rows, img_cols), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_rows, img_cols),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)\n",
        "x_batch, y_batch = next(train_generator)\n",
        "x_batch.shape\n",
        "# Plot Generator images.  ** Re-run the cell to view different set of images.\n",
        "\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "\n",
        "for i in range(8):\n",
        "    sub = fig.add_subplot(2, 4, i + 1)\n",
        "    sub.imshow(x_batch[i,:,:], interpolation='nearest')\n",
        "nb_classes = 200\n",
        "#nb_epoch = 100\n",
        "img_channels = 3\n",
        "model = ResnetBuilder.build_resnet_50_pyramid((img_channels,img_rows,img_cols), nb_classes)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "#model.summary()\n",
        "\n",
        "#model.fit_generator(train_generator, ep`ochs=nb_epoch, steps_per_epoch=200, validation_steps=200, validation_data=validation_generator\n",
        "##steps_per_epoch=Integer. Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. \n",
        "#It should typically be equal to ceil(num_samples / batch_size) Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.\n",
        "##validation_steps=Only relevant if validation_data is a generator. Total number of steps (batches of samples) to yield from validation_data generator before stopping at the end of every epoch. \n",
        "#It should typically be equal to the number of samples of your validation dataset divided by the batch size. Optional for Sequence: if unspecified, will use the len(validation_data) as a number of steps.\n",
        "##epochs: Integer. Number of epochs to train the model. An epoch is an iteration over the entire data provided, as defined by steps_per_epoch. \n",
        "#Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs,\n",
        "#but merely until the epoch of index epochs is reached.\n",
        "#steps_per_epoch=100000/200=500\n",
        "#validation_steps=10000/200=50\n",
        "#nb_epoch = 100\n",
        "# checkpoint\n",
        "filepath=\"./tiny-imagenet-200/weights.best.hdf5\"\n",
        "model.load_weights(filepath)\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "nb_epoch = 5\n",
        "model.fit_generator(train_generator, epochs=nb_epoch, steps_per_epoch=500, validation_steps=50, validation_data=validation_generator, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ORAhb_-AizTg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}