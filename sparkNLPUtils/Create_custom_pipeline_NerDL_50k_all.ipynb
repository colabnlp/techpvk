{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Create_custom_pipeline_NerDL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY5KZWu8sYEV",
        "colab_type": "text"
      },
      "source": [
        "Show how to use pretrained assertion status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpzZuBNnKXwv",
        "colab_type": "code",
        "outputId": "581bafe4-f4b0-4761-a52b-fe23cdfd11aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/Colab Notebooks/SparkNLP/utils')\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n",
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR2LZ_LQRqed",
        "colab_type": "code",
        "outputId": "099703be-fcaa-45dd-82fa-b7d560e38241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "drivepath = \"gdrive/My Drive/Colab Notebooks/SparkNLP/utils\"\n",
        "biotrainset = \"con_rest_train.bio\"\n",
        "gloveemb = \"glove.6B.300d.txt\"\n",
        "modelsavefilename=\"ner_dl_model_aug\"\n",
        "print(\"Driver path file name :\"+drivepath)\n",
        "print(\"BIO file name :\"+biotrainset)\n",
        "print(\"Glovec file name :\"+gloveemb)\n",
        "print(\"modelsavefilename file name :\"+modelsavefilename)\n",
        "!cp \"gdrive/My Drive/Colab Notebooks/SparkNLP/utils/aug_all_50k_random/aug_50k_dataset.bio\" \"con_rest_train.bio\"\n",
        "#!cp \"gdrive/My Drive/Colab Notebooks/SparkNLP/utils/aug_all_50k_eq_random/aug_full_dataset.bio\" \"con_rest_train.bio\"\n",
        "!mkdir tf\n",
        "#!cp \"gdrive/My Drive/Colab Notebooks/SparkNLP/utils/tf/81/blstm_29_300_128_81.pb\" \"./tf/blstm_29_300_128_81.pb\"\n",
        "!cp \"gdrive/My Drive/Colab Notebooks/SparkNLP/utils/tf/86/blstm_21_300_128_86.pb\" \"./tf/blstm_21_300_128_86.pb\"\n",
        "!cp \"gdrive/My Drive/Colab Notebooks/SparkNLP/utils/glove.6B.300d.txt\" \"glove.6B.300d.txt\"\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Driver path file name :gdrive/My Drive/Colab Notebooks/SparkNLP/utils\n",
            "BIO file name :con_rest_train.bio\n",
            "Glovec file name :glove.6B.300d.txt\n",
            "modelsavefilename file name :ner_dl_model_aug\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg_kFAOISDwZ",
        "colab_type": "code",
        "outputId": "082fe9c5-0472-42c6-afe5-63240eb18c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "con_rest_train.bio  gdrive  glove.6B.300d.txt  sample_data  tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIPCfwoX_9Bo",
        "colab_type": "code",
        "outputId": "cc6cbf3b-a72c-4502-d602-c3a70d4259f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.3\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.2.2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_222\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1ubuntu1~18.04.1-b10)\n",
            "OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode)\n",
            "Collecting pyspark==2.4.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/98/244399c0daa7894cdf387e7007d5e8b3710a79b67f3fd991c0b0b644822d/pyspark-2.4.3.tar.gz (215.6MB)\n",
            "\u001b[K     |████████████████████████████████| 215.6MB 63kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 41.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.3-py2.py3-none-any.whl size=215964963 sha256=7ffa4c355693f3d8e3bfce49b6cb21c17f36311e793d35bbaf9db1717421a693\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/20/f0/b30e2024226dc112e256930dd2cd4f06d00ab053c86278dcf3\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.3\n",
            "Collecting spark-nlp==2.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f9/1a/711bde42e9cd17b5166a2c282ba9824103c416091c9ad95ca7dcece7170e/spark_nlp-2.2.2-py2.py3-none-any.whl\n",
            "Installing collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xco3RwJYsYEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import PipelineModel\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import ResourceDownloader\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "if sys.version_info[0] < 3:\n",
        "    from urllib import urlretrieve\n",
        "else:\n",
        "    from urllib.request import urlretrieve    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIS_nmYYsYEa",
        "colab_type": "code",
        "outputId": "af6c987a-999b-465f-eecb-d7c1839051c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Global DEMO - Spark NLP Enterprise 2.3.4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.rdd.compress\",\"true\") \\\n",
        "    .config(\"spark.driver.memory\",\"15G\") \\\n",
        "    .config(\"spark.driver.maxResultSize\", \"2G\") \\\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "    .config(\"spark.kryoserializer.buffer.max\", \"600M\") \\\n",
        "    .config(\"spark.jars.packages\", \"JohnSnowLabs:spark-nlp:2.3.4\") \\\n",
        "    .getOrCreate()\n",
        "#spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.2\n",
            "Spark NLP version:  None\n",
            "Apache Spark version:  2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyzLAY_RDPc7",
        "colab_type": "code",
        "outputId": "75066928-cd9e-45f7-8e25-093886c41db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "!ls\n",
        "from sparknlp.training import CoNLL\n",
        "conll = CoNLL(\n",
        "    documentCol=\"document\",\n",
        "    sentenceCol=\"sentence\",\n",
        "    tokenCol=\"token\",\n",
        "    posCol=\"pos\",\n",
        "    conllLabelIndex=3,\n",
        "    conllPosIndex=1,\n",
        "    textCol='text',\n",
        "    labelCol='label',\n",
        "    explodeSentences=True\n",
        ")\n",
        "training_data = conll.readDataset(spark, 'con_rest_train.bio',ReadAs.LINE_BY_LINE)\n",
        "#training_data = CoNLL().readDataset(spark, 'con_rest_train.bio')\n",
        "training_data,test_data=training_data.randomSplit([0.9, 0.1], None)\n",
        "print(\"Training Dataset Count: \" + str(training_data.count()))\n",
        "print(\"Test Dataset Count: \" + str(test_data.count()))\n",
        "training_data.show(n=20)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "con_rest_train.bio  gdrive  glove.6B.300d.txt  sample_data  tf\n",
            "Training Dataset Count: 44912\n",
            "Test Dataset Count: 5085\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|5 star resturants...|[[document, 0, 28...|[[document, 0, 28...|[[token, 0, 0, 5,...|[[pos, 0, 0, , [w...|[[named_entity, 0...|\n",
            "|5 superstar restu...|[[document, 0, 32...|[[document, 0, 32...|[[token, 0, 0, 5,...|[[pos, 0, 0, , [w...|[[named_entity, 0...|\n",
            "|98 hong nung rest...|[[document, 0, 40...|[[document, 0, 40...|[[token, 0, 1, 98...|[[pos, 0, 1, , [w...|[[named_entity, 0...|\n",
            "|Are there any pla...|[[document, 0, 69...|[[document, 0, 69...|[[token, 0, 2, Ar...|[[pos, 0, 2, , [w...|[[named_entity, 0...|\n",
            "|At Meal time whil...|[[document, 0, 43...|[[document, 0, 43...|[[token, 0, 1, At...|[[pos, 0, 1, , [w...|[[named_entity, 0...|\n",
            "|At dinner time wh...|[[document, 0, 45...|[[document, 0, 45...|[[token, 0, 1, At...|[[pos, 0, 1, , [w...|[[named_entity, 0...|\n",
            "|At thirteen hundr...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 1, At...|[[pos, 0, 1, , [w...|[[named_entity, 0...|\n",
            "|At thirteen hundr...|[[document, 0, 63...|[[document, 0, 63...|[[token, 0, 1, At...|[[pos, 0, 1, , [w...|[[named_entity, 0...|\n",
            "|At thirteen hundr...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 1, At...|[[pos, 0, 1, , [w...|[[named_entity, 0...|\n",
            "|At thirteen hundr...|[[document, 0, 62...|[[document, 0, 62...|[[token, 0, 1, At...|[[pos, 0, 1, , [w...|[[named_entity, 0...|\n",
            "|At thirteen hundr...|[[document, 0, 62...|[[document, 0, 62...|[[token, 0, 1, At...|[[pos, 0, 1, , [w...|[[named_entity, 0...|\n",
            "|At thirteen hundr...|[[document, 0, 67...|[[document, 0, 67...|[[token, 0, 1, At...|[[pos, 0, 1, , [w...|[[named_entity, 0...|\n",
            "|At thirteen hundr...|[[document, 0, 69...|[[document, 0, 69...|[[token, 0, 1, At...|[[pos, 0, 1, , [w...|[[named_entity, 0...|\n",
            "|BBQ ribs and beer...|[[document, 0, 27...|[[document, 0, 27...|[[token, 0, 2, BB...|[[pos, 0, 2, , [w...|[[named_entity, 0...|\n",
            "|  BomBom dees please|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 5, Bo...|[[pos, 0, 5, , [w...|[[named_entity, 0...|\n",
            "|              Brunch|[[document, 0, 5,...|[[document, 0, 5,...|[[token, 0, 5, Br...|[[pos, 0, 5, , [w...|[[named_entity, 0...|\n",
            "|Can you give me t...|[[document, 0, 44...|[[document, 0, 44...|[[token, 0, 2, Ca...|[[pos, 0, 2, , [w...|[[named_entity, 0...|\n",
            "|Can you give me t...|[[document, 0, 37...|[[document, 0, 37...|[[token, 0, 2, Ca...|[[pos, 0, 2, , [w...|[[named_entity, 0...|\n",
            "|Can you give me t...|[[document, 0, 65...|[[document, 0, 65...|[[token, 0, 2, Ca...|[[pos, 0, 2, , [w...|[[named_entity, 0...|\n",
            "|Can you give me t...|[[document, 0, 68...|[[document, 0, 68...|[[token, 0, 2, Ca...|[[pos, 0, 2, , [w...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ3gvJQHsYEf",
        "colab_type": "text"
      },
      "source": [
        "Create a custom pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGWDh6y7sYEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "embeddings = WordEmbeddings() \\\n",
        "        .setInputCols([\"document\", \"token\"])\\\n",
        "        .setOutputCol(\"embeddings\")\\\n",
        "        .setEmbeddingsSource(\"glove.6B.300d.txt\", 300, \"text\")\n",
        "\n",
        "#spell = NorvigSweetingModel.pretrained() \\\n",
        "#    .setInputCols([\"token\"]) \\\n",
        "#    .setOutputCol(\"spell\")\n",
        "#.setGraphFolder(\"gdrive/My Drive/Colab Notebooks/SparkNLP/utils/Graphs\")\\\n",
        "ner_dl = NerDLApproach()\\\n",
        "    .setInputCols([\"document\", \"token\",\"embeddings\"])\\\n",
        "    .setLabelColumn(\"label\")\\\n",
        "    .setOutputCol(\"ner\")\\\n",
        "    .setMaxEpochs(2)\\\n",
        "    .setRandomSeed(0)\\\n",
        "    .setVerbose(2)\\\n",
        "    .setBatchSize(10)\\\n",
        "    .setGraphFolder(\"./tf/\")\\\n",
        "    .setEnableOutputLogs(True)\n",
        "\n",
        "converter = NerConverter()\\\n",
        "  .setInputCols([\"document\", \"token\", \"ner\"])\\\n",
        "  .setOutputCol(\"ner_converter\")\n",
        "\n",
        "finisher = Finisher() \\\n",
        "    .setInputCols([\"ner\", \"ner_converter\"]) \\\n",
        "    .setIncludeMetadata(True)\n",
        "\n",
        "pipeline_fast_dl = Pipeline(stages = [\n",
        "    documentAssembler, \n",
        "    tokenizer, \n",
        "    embeddings, \n",
        "    ner_dl,\n",
        "    converter,\n",
        "    finisher])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m8RfeZZsYEi",
        "colab_type": "text"
      },
      "source": [
        "Now let's use these pipelines and see the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO_qeaCQDcDC",
        "colab_type": "code",
        "outputId": "d2e0519d-1bd6-40f6-dce6-8b1fe61eda9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "start = time.time()\n",
        "print(\"Start fitting\")\n",
        "prediction_model = pipeline_fast_dl.fit(training_data)\n",
        "print(\"Fitting is ended\")\n",
        "print (time.time() - start)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start fitting\n",
            "Fitting is ended\n",
            "1717.20232629776\n",
            "CPU times: user 284 ms, sys: 72.1 ms, total: 356 ms\n",
            "Wall time: 28min 37s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK-J83PbffUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "3b2dd7c9-ca84-4192-ed4c-e52bdbcde975"
      },
      "source": [
        "#prediction_data = spark.createDataFrame([[\"Maria is a nice place.\"],[\"any bbq places open before 5 nearby\"]]).toDF(\"text\")\n",
        "#prediction_data.show()\n",
        "prediction_model.transform(test_data).show(truncate=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|text                                                                                                     |finished_ner                                                                                                                                                                            |finished_ner_converter                                                 |finished_ner_metadata                                                                                                                                                                                                                                                       |finished_ner_converter_metadata                                                                                                                                                                             |\n",
            "+---------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Can you give me the forecast for Keytesville for 12 minutes from already                                 |[O, O, O, O, O, O, O, B-Location, O, B-weather_duration, I-weather_duration, I-weather_duration, I-weather_duration]                                                                    |[Keytesville, 12 minutes from already]                                 |[[word, Can], [word, you], [word, give], [word, me], [word, the], [word, forecast], [word, for], [word, Keytesville], [word, for], [word, 12], [word, minutes], [word, from], [word, already]]                                                                              |[[entity, Location], [sentence, 0], [chunk, 0], [entity, weather_duration], [sentence, 0], [chunk, 1]]                                                                                                      |\n",
            "|Can you give me the forecast for Keytesville for 12 minutes where now                                    |[O, O, O, O, O, O, O, B-Location, O, B-weather_duration, I-weather_duration, I-weather_duration, I-weather_duration]                                                                    |[Keytesville, 12 minutes where now]                                    |[[word, Can], [word, you], [word, give], [word, me], [word, the], [word, forecast], [word, for], [word, Keytesville], [word, for], [word, 12], [word, minutes], [word, where], [word, now]]                                                                                 |[[entity, Location], [sentence, 0], [chunk, 0], [entity, weather_duration], [sentence, 0], [chunk, 1]]                                                                                                      |\n",
            "|Can you give me the weather forecast for Nov. 9th for Lakeview Place_Apartments , LA                     |[O, O, O, O, O, O, O, O, O, O, I-weather_duration, O, B-Location, I-Location, O, B-Location]                                                                                            |[9th, Lakeview Place_Apartments, LA]                                   |[[word, Can], [word, you], [word, give], [word, me], [word, the], [word, weather], [word, forecast], [word, for], [word, Nov], [word, .], [word, 9th], [word, for], [word, Lakeview], [word, Place_Apartments], [word, ,], [word, LA]]                                      |[[entity, weather_duration], [sentence, 0], [chunk, 0], [entity, Location], [sentence, 0], [chunk, 1], [entity, Location], [sentence, 0], [chunk, 2]]                                                       |\n",
            "|Can you tell me if it'll be freezing in Wrightstown in ## years ?                                        |[O, O, O, O, O, O, O, B-weather_temperature, O, B-Location, B-weather_duration, I-weather_duration, I-weather_duration, O]                                                              |[freezing, Wrightstown, in ## years]                                   |[[word, Can], [word, you], [word, tell], [word, me], [word, if], [word, it'll], [word, be], [word, freezing], [word, in], [word, Wrightstown], [word, in], [word, ##], [word, years], [word, ?]]                                                                            |[[entity, weather_temperature], [sentence, 0], [chunk, 0], [entity, Location], [sentence, 0], [chunk, 1], [entity, weather_duration], [sentence, 0], [chunk, 2]]                                            |\n",
            "|Can you tell me the forecast for East Falmouth , Latvia                                                  |[O, O, O, O, O, O, O, B-Location, I-Location, O, B-Location]                                                                                                                            |[East Falmouth, Latvia]                                                |[[word, Can], [word, you], [word, tell], [word, me], [word, the], [word, forecast], [word, for], [word, East], [word, Falmouth], [word, ,], [word, Latvia]]                                                                                                                 |[[entity, Location], [sentence, 0], [chunk, 0], [entity, Location], [sentence, 0], [chunk, 1]]                                                                                                              |\n",
            "|Can you tell me the forecast for Southeast Falmouth , Hungary                                            |[O, O, O, O, O, O, O, B-Location, I-Location, O, B-Location]                                                                                                                            |[Southeast Falmouth, Hungary]                                          |[[word, Can], [word, you], [word, tell], [word, me], [word, the], [word, forecast], [word, for], [word, Southeast], [word, Falmouth], [word, ,], [word, Hungary]]                                                                                                           |[[entity, Location], [sentence, 0], [chunk, 0], [entity, Location], [sentence, 0], [chunk, 1]]                                                                                                              |\n",
            "|Can you tell me what the weather is doing in North Eliah_Jembere , Guam                                  |[O, O, O, O, O, O, O, O, O, O, B-Location, I-Location, O, B-Location]                                                                                                                   |[North Eliah_Jembere, Guam]                                            |[[word, Can], [word, you], [word, tell], [word, me], [word, what], [word, the], [word, weather], [word, is], [word, doing], [word, in], [word, North], [word, Eliah_Jembere], [word, ,], [word, Guam]]                                                                      |[[entity, Location], [sentence, 0], [chunk, 0], [entity, Location], [sentence, 0], [chunk, 1]]                                                                                                              |\n",
            "|Can you tell me what the weather is doing in theSouth Epworth , Guam                                     |[O, O, O, O, O, O, O, O, O, O, B-Location, I-Location, O, B-Location]                                                                                                                   |[theSouth Epworth, Guam]                                               |[[word, Can], [word, you], [word, tell], [word, me], [word, what], [word, the], [word, weather], [word, is], [word, doing], [word, in], [word, theSouth], [word, Epworth], [word, ,], [word, Guam]]                                                                         |[[entity, Location], [sentence, 0], [chunk, 0], [entity, Location], [sentence, 0], [chunk, 1]]                                                                                                              |\n",
            "|Check the forecast for Natchaug Stae Forest                                                              |[O, O, O, O, B-Location, I-Location, I-Location]                                                                                                                                        |[Natchaug Stae Forest]                                                 |[[word, Check], [word, the], [word, forecast], [word, for], [word, Natchaug], [word, Stae], [word, Forest]]                                                                                                                                                                 |[[entity, Location], [sentence, 0], [chunk, 0]]                                                                                                                                                             |\n",
            "|Check the forecast for the current spot in the future May 19, 2037 .                                     |[O, O, O, O, O, B-Location, I-Location, O, O, B-weather_duration, I-weather_duration, O, O, I-weather_duration, O]                                                                      |[current spot, future May, 2037]                                       |[[word, Check], [word, the], [word, forecast], [word, for], [word, the], [word, current], [word, spot], [word, in], [word, the], [word, future], [word, May], [word, 19], [word, ,], [word, 2037], [word, .]]                                                               |[[entity, Location], [sentence, 0], [chunk, 0], [entity, weather_duration], [sentence, 0], [chunk, 1], [entity, weather_duration], [sentence, 0], [chunk, 2]]                                               |\n",
            "|Check the weather for Kenedy , Vanuatu for around eight am                                               |[O, O, O, O, B-Location, O, B-Location, O, O, B-weather_duration, I-weather_duration]                                                                                                   |[Kenedy, Vanuatu, eight am]                                            |[[word, Check], [word, the], [word, weather], [word, for], [word, Kenedy], [word, ,], [word, Vanuatu], [word, for], [word, around], [word, eight], [word, am]]                                                                                                              |[[entity, Location], [sentence, 0], [chunk, 0], [entity, Location], [sentence, 0], [chunk, 1], [entity, weather_duration], [sentence, 0], [chunk, 2]]                                                       |\n",
            "|Check the weather forecast for Sappho                                                                    |[O, O, O, O, O, B-Location]                                                                                                                                                             |[Sappho]                                                               |[[word, Check], [word, the], [word, weather], [word, forecast], [word, for], [word, Sappho]]                                                                                                                                                                                |[[entity, Location], [sentence, 0], [chunk, 0]]                                                                                                                                                             |\n",
            "|Give me Slovakia 's weather forecast for eight am                                                        |[O, O, B-Location, O, O, O, O, O, B-weather_duration, I-weather_duration]                                                                                                               |[Slovakia, eight am]                                                   |[[word, Give], [word, me], [word, Slovakia], [word, '], [word, s], [word, weather], [word, forecast], [word, for], [word, eight], [word, am]]                                                                                                                               |[[entity, Location], [sentence, 0], [chunk, 0], [entity, weather_duration], [sentence, 0], [chunk, 1]]                                                                                                      |\n",
            "|Give me in weather forecast for Wisconsin Dells in Saint Kitts and Nevis on in day after tomorrow        |[O, O, O, O, O, O, B-Location, I-Location, O, B-Location, I-Location, I-Location, I-Location, O, B-weather_duration, I-weather_duration, I-weather_duration, I-weather_duration]        |[Wisconsin Dells, Saint Kitts and Nevis, in day after tomorrow]        |[[word, Give], [word, me], [word, in], [word, weather], [word, forecast], [word, for], [word, Wisconsin], [word, Dells], [word, in], [word, Saint], [word, Kitts], [word, and], [word, Nevis], [word, on], [word, in], [word, day], [word, after], [word, tomorrow]]        |[[entity, Location], [sentence, 0], [chunk, 0], [entity, Location], [sentence, 0], [chunk, 1], [entity, weather_duration], [sentence, 0], [chunk, 2]]                                                       |\n",
            "|Give me the forecast for feb. eleventh, 2034 much from Alaska                                            |[O, O, O, O, O, O, O, O, O, I-weather_duration, B-Location, O, B-Location]                                                                                                              |[2034, much, Alaska]                                                   |[[word, Give], [word, me], [word, the], [word, forecast], [word, for], [word, feb], [word, .], [word, eleventh], [word, ,], [word, 2034], [word, much], [word, from], [word, Alaska]]                                                                                       |[[entity, weather_duration], [sentence, 0], [chunk, 0], [entity, Location], [sentence, 0], [chunk, 1], [entity, Location], [sentence, 0], [chunk, 2]]                                                       |\n",
            "|Give me the forecast for the weather in Citrus Springs                                                   |[O, O, O, O, O, O, O, O, B-Location, I-Location]                                                                                                                                        |[Citrus Springs]                                                       |[[word, Give], [word, me], [word, the], [word, forecast], [word, for], [word, the], [word, weather], [word, in], [word, Citrus], [word, Springs]]                                                                                                                           |[[entity, Location], [sentence, 0], [chunk, 0]]                                                                                                                                                             |\n",
            "|Give me the weather forecast for Wisconsin Dells in St Kitts and Nevis on the day after tomorrow         |[O, O, O, O, O, O, B-Location, I-Location, O, B-Location, I-Location, I-Location, I-Location, O, B-weather_duration, I-weather_duration, I-weather_duration, I-weather_duration]        |[Wisconsin Dells, St Kitts and Nevis, the day after tomorrow]          |[[word, Give], [word, me], [word, the], [word, weather], [word, forecast], [word, for], [word, Wisconsin], [word, Dells], [word, in], [word, St], [word, Kitts], [word, and], [word, Nevis], [word, on], [word, the], [word, day], [word, after], [word, tomorrow]]         |[[entity, Location], [sentence, 0], [chunk, 0], [entity, Location], [sentence, 0], [chunk, 1], [entity, weather_duration], [sentence, 0], [chunk, 2]]                                                       |\n",
            "|Give me the weather forecast for Wisconsin Lake_Delton in Saint Kitts and Nevis on the day after tomorrow|[O, O, O, O, O, O, B-Location, B-weather_duration, O, B-Location, I-Location, I-Location, I-Location, O, B-weather_duration, I-weather_duration, I-weather_duration, I-weather_duration]|[Wisconsin, Lake_Delton, Saint Kitts and Nevis, the day after tomorrow]|[[word, Give], [word, me], [word, the], [word, weather], [word, forecast], [word, for], [word, Wisconsin], [word, Lake_Delton], [word, in], [word, Saint], [word, Kitts], [word, and], [word, Nevis], [word, on], [word, the], [word, day], [word, after], [word, tomorrow]]|[[entity, Location], [sentence, 0], [chunk, 0], [entity, weather_duration], [sentence, 0], [chunk, 1], [entity, Location], [sentence, 0], [chunk, 2], [entity, weather_duration], [sentence, 0], [chunk, 3]]|\n",
            "|Give me the weather forecast for Wisconsin Northwoods in Saint Kitts and Nevis on the day after tomorrow |[O, O, O, O, O, O, B-Location, I-Location, O, B-Location, I-Location, I-Location, I-Location, O, B-weather_duration, I-weather_duration, I-weather_duration, I-weather_duration]        |[Wisconsin Northwoods, Saint Kitts and Nevis, the day after tomorrow]  |[[word, Give], [word, me], [word, the], [word, weather], [word, forecast], [word, for], [word, Wisconsin], [word, Northwoods], [word, in], [word, Saint], [word, Kitts], [word, and], [word, Nevis], [word, on], [word, the], [word, day], [word, after], [word, tomorrow]] |[[entity, Location], [sentence, 0], [chunk, 0], [entity, Location], [sentence, 0], [chunk, 1], [entity, weather_duration], [sentence, 0], [chunk, 2]]                                                       |\n",
            "|Give me the weather forecast in Boma for next winter                                                     |[O, O, O, O, O, O, B-Location, O, B-weather_duration, I-weather_duration]                                                                                                               |[Boma, next winter]                                                    |[[word, Give], [word, me], [word, the], [word, weather], [word, forecast], [word, in], [word, Boma], [word, for], [word, next], [word, winter]]                                                                                                                             |[[entity, Location], [sentence, 0], [chunk, 0], [entity, weather_duration], [sentence, 0], [chunk, 1]]                                                                                                      |\n",
            "+---------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p63iLEmxb0ab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "47edf21a-0358-407f-93b5-60ab5a01b6e2"
      },
      "source": [
        "prediction_data = spark.createDataFrame([[\"what is the whtr in bangalore karnataka\"],[\"find Nearest restarent\"],[[\"find Nearest pizza restarent\"]]]).toDF(\"text\")\n",
        "prediction_data.show(truncate=False)\n",
        "prediction_model.transform(prediction_data).show(truncate=False)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ae514c042b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"what is the whtr in bangalore karnataka\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"find Nearest restarent\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"find Nearest pizza restarent\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprediction_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoJavaArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplySchemaToPythonRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchemaFromList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_inferSchemaFromList\u001b[0;34m(self, data, names)\u001b[0m\n\u001b[1;32m    346\u001b[0m             warnings.warn(\"inferring schema from dict is deprecated,\"\n\u001b[1;32m    347\u001b[0m                           \"please use pyspark.sql.Row instead\")\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_merge_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_infer_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_has_nulltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Some of types cannot be determined after inferring\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/types.py\u001b[0m in \u001b[0;36m_merge_type\u001b[0;34m(a, b, name)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         fields = [StructField(f.name, _merge_type(f.dataType, nfs.get(f.name, NullType()),\n\u001b[1;32m   1100\u001b[0m                                                   name=new_name(f.name)))\n\u001b[0;32m-> 1101\u001b[0;31m                   for f in a.fields]\n\u001b[0m\u001b[1;32m   1102\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/types.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         fields = [StructField(f.name, _merge_type(f.dataType, nfs.get(f.name, NullType()),\n\u001b[1;32m   1100\u001b[0m                                                   name=new_name(f.name)))\n\u001b[0;32m-> 1101\u001b[0;31m                   for f in a.fields]\n\u001b[0m\u001b[1;32m   1102\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/types.py\u001b[0m in \u001b[0;36m_merge_type\u001b[0;34m(a, b, name)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;31m# TODO: type cast (such as int -> long)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not merge type %s and %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[0;31m# same type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: field _1: Can not merge type <class 'pyspark.sql.types.StringType'> and <class 'pyspark.sql.types.ArrayType'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ov6Vcf2ERg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_model.write().overwrite().save(\"ner_dl_model_aug\")\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4TsjFNr3xJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r 'ner_dl_model_aug' 'gdrive/My Drive/Colab Notebooks/SparkNLP/utils/ner_dl_model_aug'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86pAku0iETDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml import PipelineModel, Pipeline\n",
        "\n",
        "loaded_prediction_model = PipelineModel.read().load('ner_dl_model_aug')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqO9vjyZGMzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_data = spark.createDataFrame([[\"Maria is a nice place.\"],[\"any bbq places open before 5 nearby\"],[\"2 star restaurants with inside dining\"],['98 hong kong restaurant reasonable prices']]).toDF(\"text\")\n",
        "prediction_data.show()\n",
        "loaded_prediction_model.transform(prediction_data).show(truncate=False)\n",
        "prediction = loaded_prediction_model.transform(prediction_data)\n",
        "prediction.select(\"finished_ner_metadata\").show(truncate=False)\n",
        "prediction.select(\"finished_ner\").show(truncate=False)\n",
        "prediction.select(\"finished_ner_converter_metadata\").show(truncate=False)\n",
        "prediction.select(\"finished_ner_converter\").show(truncate=False)\n",
        "#prediction.select(\"ner\").show(truncate=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}