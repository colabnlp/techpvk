{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tech_pvk_approch_working_23_03_of Vkt_TinyImageNet_StarterNotebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/techpvk/techpvk/blob/master/tech_pvk_approch_working_23_03_of_Vkt_TinyImageNet_StarterNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "I4th9KTGttp2",
        "colab_type": "code",
        "outputId": "d6aaa400-7f21-4268-92df-710f59d0f137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# List and Clear the Data first\n",
        "!ls\n",
        "#!rm -rf sample_data tiny-imagenet-200\ttiny-imagenet-200.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Atw96-N2TqIJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# list content after the clearing data\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2-uxInsGaQTb",
        "colab_type": "code",
        "outputId": "254028c3-fe76-4b59-8e6b-7e8280763fc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Download the file\n",
        "#!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-24 08:39:38--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  20.7MB/s    in 14s     \n",
            "\n",
            "2019-03-24 08:39:53 (16.7 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "phm86ZULdPa1",
        "colab_type": "code",
        "outputId": "f1018c6a-c352-407f-d8ef-5e1f969dacaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#unzip and list\n",
        "#!unzip -qq 'tiny-imagenet-200.zip'\n",
        "#!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tiny-imagenet-200  tiny-imagenet-200.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7l_PCFURg9x_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6947dd7-1d64-433e-f395-26e5fd1ba905"
      },
      "cell_type": "code",
      "source": [
        "# import the required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import six\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from __future__ import division\n",
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Activation,\n",
        "    Dense,\n",
        "    Flatten,\n",
        "    Dropout\n",
        ")\n",
        "from keras.layers.convolutional import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    AveragePooling2D\n",
        ")\n",
        "from keras.layers.merge import add\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.models import model_from_yaml"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "r7SjAhI2Jskn",
        "colab_type": "code",
        "outputId": "68ddcaa8-3c14-490f-b10b-e752d02b413b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "val_data.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>val_0.JPEG</td>\n",
              "      <td>n03444034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>val_1.JPEG</td>\n",
              "      <td>n04067472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>val_2.JPEG</td>\n",
              "      <td>n04070727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>val_3.JPEG</td>\n",
              "      <td>n02808440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>val_4.JPEG</td>\n",
              "      <td>n02808440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>val_5.JPEG</td>\n",
              "      <td>n04399382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>val_6.JPEG</td>\n",
              "      <td>n04179913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>val_7.JPEG</td>\n",
              "      <td>n02823428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>val_8.JPEG</td>\n",
              "      <td>n04146614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>val_9.JPEG</td>\n",
              "      <td>n02226429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         File      Class\n",
              "0  val_0.JPEG  n03444034\n",
              "1  val_1.JPEG  n04067472\n",
              "2  val_2.JPEG  n04070727\n",
              "3  val_3.JPEG  n02808440\n",
              "4  val_4.JPEG  n02808440\n",
              "5  val_5.JPEG  n04399382\n",
              "6  val_6.JPEG  n04179913\n",
              "7  val_7.JPEG  n02823428\n",
              "8  val_8.JPEG  n04146614\n",
              "9  val_9.JPEG  n02226429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "wRYLyZtwKKDp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use Augmentaion parameters as required.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    zoom_range = 0.3,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True\n",
        "    )\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "igYtU_VSKXto",
        "colab_type": "code",
        "outputId": "4ce310a4-bba9-4d20-b5db-7b5cb591d170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(32, 32), color_mode='rgb', \n",
        "                                                    batch_size=200, class_mode='categorical', shuffle=True, seed=42)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UBRfC4SdKbca",
        "colab_type": "code",
        "outputId": "42ebecaf-d401-4345-c2d9-d78abaa72e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(32, 32),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=200, shuffle=True, seed=42)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4AfmUc4gxPg6",
        "colab_type": "code",
        "outputId": "8abc7fc6-c2c9-49d3-a5d2-727c31109dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(train_generator)\n",
        "x_batch.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "CsK7MXV_wZS8",
        "colab_type": "code",
        "outputId": "b4c2f4b8-c7f0-4325-af71-ad79d8af1920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot Generator images.  ** Re-run the cell to view different set of images.\n",
        "\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "\n",
        "for i in range(8):\n",
        "    sub = fig.add_subplot(2, 4, i + 1)\n",
        "    sub.imshow(x_batch[i,:,:], interpolation='nearest')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAv8AAAExCAYAAADr8c17AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCw5rI6TRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1008x360 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pfHaHidXMWM3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _bn_relu(input):\n",
        "    \"\"\"Helper to build a BN -> relu block\n",
        "    \"\"\"\n",
        "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
        "    return Activation(\"relu\")(norm)\n",
        "\n",
        "\n",
        "def _conv_bn_relu(**conv_params):\n",
        "    \"\"\"Helper to build a conv -> BN -> relu block\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(input)\n",
        "        return _bn_relu(conv)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _bn_relu_conv(**conv_params):\n",
        "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
        "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        activation = _bn_relu(input)\n",
        "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(activation)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _shortcut(input, residual):\n",
        "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
        "    \"\"\"\n",
        "    # Expand channels of shortcut to match residual.\n",
        "    # Stride appropriately to match residual (width, height)\n",
        "    # Should be int if network architecture is correctly configured.\n",
        "    input_shape = K.int_shape(input)\n",
        "    residual_shape = K.int_shape(residual)\n",
        "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
        "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
        "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
        "\n",
        "    shortcut = input\n",
        "    # 1 X 1 conv if shape is different. Else identity.\n",
        "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
        "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=(stride_width, stride_height),\n",
        "                          padding=\"valid\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.0001))(input)\n",
        "\n",
        "    return add([shortcut, residual])\n",
        "\n",
        "\n",
        "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
        "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        for i in range(repetitions):\n",
        "            init_strides = (1, 1)\n",
        "            if i == 0 and not is_first_layer:\n",
        "                init_strides = (2, 2)\n",
        "            input = block_function(filters=filters, init_strides=init_strides,\n",
        "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
        "        return input\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
        "                           strides=init_strides,\n",
        "                           padding=\"same\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
        "                                  strides=init_strides)(input)\n",
        "\n",
        "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    Returns:\n",
        "        A final conv layer of filters * 4\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
        "                              strides=init_strides,\n",
        "                              padding=\"same\",\n",
        "                              kernel_initializer=\"he_normal\",\n",
        "                              kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
        "                                     strides=init_strides)(input)\n",
        "\n",
        "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
        "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _handle_dim_ordering():\n",
        "    global ROW_AXIS\n",
        "    global COL_AXIS\n",
        "    global CHANNEL_AXIS\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        ROW_AXIS = 1\n",
        "        COL_AXIS = 2\n",
        "        CHANNEL_AXIS = 3\n",
        "    else:\n",
        "        CHANNEL_AXIS = 1\n",
        "        ROW_AXIS = 2\n",
        "        COL_AXIS = 3\n",
        "\n",
        "\n",
        "def _get_block(identifier):\n",
        "    if isinstance(identifier, six.string_types):\n",
        "        res = globals().get(identifier)\n",
        "        if not res:\n",
        "            raise ValueError('Invalid {}'.format(identifier))\n",
        "        return res\n",
        "    return identifier\n",
        "\n",
        "\n",
        "class ResnetBuilder(object):\n",
        "    @staticmethod\n",
        "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
        "        \"\"\"Builds a custom ResNet like architecture.\n",
        "        Args:\n",
        "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
        "            num_outputs: The number of outputs at final softmax layer\n",
        "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
        "                The original paper used basic_block for layers < 50\n",
        "            repetitions: Number of repetitions of various block units.\n",
        "                At each block unit, the number of filters are doubled and the input size is halved\n",
        "        Returns:\n",
        "            The keras `Model`.\n",
        "        \"\"\"\n",
        "        _handle_dim_ordering()\n",
        "        if len(input_shape) != 3:\n",
        "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
        "\n",
        "        # Permute dimension order if necessary\n",
        "        if K.image_dim_ordering() == 'tf':\n",
        "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
        "\n",
        "        # Load function from str if needed.\n",
        "        block_fn = _get_block(block_fn)\n",
        "\n",
        "        input = Input(shape=input_shape)\n",
        "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
        "        #pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
        "        block = conv1\n",
        "        filters = 64\n",
        "        for i, r in enumerate(repetitions):\n",
        "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
        "            filters *= 2\n",
        "\n",
        "        # Last activation\n",
        "        block = _bn_relu(block)\n",
        "\n",
        "        # Classifier block\n",
        "        block_shape = K.int_shape(block)\n",
        "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
        "                                 strides=(1, 1))(block)\n",
        "        flatten1 = Flatten()(pool2)\n",
        "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
        "                     activation=\"softmax\")(flatten1)\n",
        "        model = Model(inputs=input, outputs=dense)\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_18(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_34(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_50(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_101(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_152(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wnzu2sLmx7Az",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "698cdaaa-fd05-4748-9788-00e972635505"
      },
      "cell_type": "code",
      "source": [
        "nb_classes = 200\n",
        "#nb_epoch = 100\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 32, 32\n",
        "img_channels = 3\n",
        "model = ResnetBuilder.build_resnet_50((img_channels, img_rows, img_cols), nb_classes)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JmByD_YOZDss",
        "colab_type": "code",
        "outputId": "f48cd49d-65c1-4ec3-a266-33e7e75aee69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plot_model(model, to_file='./tiny-imagenet-200/model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "items = os.listdir('./tiny-imagenet-200')\n",
        "print (items)    \n",
        "image = cv2.imread('./tiny-imagenet-200/model_plot.png')\n",
        "image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "plt.figure()\n",
        "plt.imshow(image)\n",
        "plt.colorbar()\n",
        "plt.grid(False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['train', 'model_plot.png', 'words.txt', 'val', 'wnids.txt', 'test']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAAFOCAYAAABdfFVPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8n9aiFoS4r7AqAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "on2zXDUMyC8Z",
        "colab_type": "code",
        "outputId": "f95709a5-2951-4961-9a47-7959b916209a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6222
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 16, 16, 64)   9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 16, 16, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16, 16, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 64)   4160        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 16, 16, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 16, 16, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 16, 16, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 16, 16, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 16, 16, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 256)  16640       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 16, 16, 256)  0           conv2d_5[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 16, 16, 256)  1024        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 256)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 64)   256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 256)  0           add_1[0][0]                      \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 256)  1024        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 256)  0           add_2[0][0]                      \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 256)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 8, 8, 128)    32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 8, 8, 128)    512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 8, 8, 128)    0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 128)    147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 8, 8, 128)    512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 128)    0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 512)    131584      add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 512)    66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 512)    0           conv2d_15[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 512)    2048        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 512)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 128)    65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 128)    512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 128)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 128)    147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 128)    512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 128)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 512)    66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 512)    0           add_4[0][0]                      \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 512)    2048        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 512)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 128)    65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 128)    512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 128)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 128)    147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 128)    512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 128)    0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 512)    66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 512)    0           add_5[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 512)    2048        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 512)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 128)    65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 128)    512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 8, 8, 128)    0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 128)    147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 128)    512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 128)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 8, 8, 512)    66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 512)    0           add_6[0][0]                      \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 512)    2048        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 512)    0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 4, 4, 256)    131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 4, 4, 256)    1024        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 4, 4, 256)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 4, 4, 256)    590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 4, 4, 256)    1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 4, 4, 256)    0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 4, 4, 1024)   525312      add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 4, 4, 1024)   263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 4, 4, 1024)   0           conv2d_28[0][0]                  \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 4, 4, 1024)   4096        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 4, 4, 256)    262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 4, 4, 256)    1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 4, 4, 256)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 4, 4, 256)    590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 4, 4, 256)    1024        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 4, 4, 256)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 4, 4, 1024)   263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 4, 4, 1024)   0           add_8[0][0]                      \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 4, 4, 1024)   4096        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 4, 4, 256)    262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 4, 4, 256)    1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 4, 4, 256)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 4, 4, 256)    590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 4, 4, 256)    1024        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 4, 4, 256)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 4, 4, 1024)   263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 4, 4, 1024)   0           add_9[0][0]                      \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 4, 4, 1024)   4096        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 4, 4, 256)    262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 4, 4, 256)    1024        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 4, 4, 256)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 4, 4, 256)    590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 4, 4, 256)    1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 4, 4, 256)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 4, 4, 1024)   263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 4, 4, 1024)   0           add_10[0][0]                     \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 4, 4, 1024)   4096        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 4, 4, 256)    262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 4, 4, 256)    1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 4, 4, 256)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 4, 4, 256)    590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 4, 4, 256)    1024        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 4, 4, 256)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 1024)   263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 4, 4, 1024)   0           add_11[0][0]                     \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 4, 4, 1024)   4096        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 4, 4, 256)    262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 4, 4, 256)    1024        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 4, 4, 256)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 256)    590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 4, 256)    1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 4, 4, 256)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 1024)   263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 4, 4, 1024)   0           add_12[0][0]                     \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 4, 4, 1024)   4096        add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 2, 2, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 2, 2, 512)    2048        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 2, 2, 512)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 2, 2, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 2, 2, 512)    2048        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 2, 2, 512)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 2, 2, 2048)   2099200     add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 2, 2, 2048)   0           conv2d_47[0][0]                  \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 2, 2, 2048)   8192        add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 2, 2, 2048)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 2, 2, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 2, 2, 512)    2048        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 2, 2, 512)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 2, 2, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 2, 2, 512)    2048        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 2, 2, 512)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 2, 2, 2048)   8192        add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 2, 2, 2048)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 2, 2, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 2, 2, 512)    2048        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 2, 2, 512)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 2, 2, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 2, 2, 512)    2048        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 2, 2, 512)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 2, 2, 2048)   8192        add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 2, 2, 2048)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 2048)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 200)          409800      flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,982,152\n",
            "Trainable params: 23,936,712\n",
            "Non-trainable params: 45,440\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8V-LArlmyFyX",
        "colab_type": "code",
        "outputId": "616924de-9e2e-4d83-e42d-7688f77a5cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4134
        }
      },
      "cell_type": "code",
      "source": [
        "#model.fit_generator(train_generator, epochs=nb_epoch, steps_per_epoch=200, validation_steps=200, validation_data=validation_generator\n",
        "##steps_per_epoch=Integer. Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. \n",
        "#It should typically be equal to ceil(num_samples / batch_size) Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.\n",
        "##validation_steps=Only relevant if validation_data is a generator. Total number of steps (batches of samples) to yield from validation_data generator before stopping at the end of every epoch. \n",
        "#It should typically be equal to the number of samples of your validation dataset divided by the batch size. Optional for Sequence: if unspecified, will use the len(validation_data) as a number of steps.\n",
        "##epochs: Integer. Number of epochs to train the model. An epoch is an iteration over the entire data provided, as defined by steps_per_epoch. \n",
        "#Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs,\n",
        "#but merely until the epoch of index epochs is reached.\n",
        "#steps_per_epoch=100000/200=500\n",
        "#validation_steps=10000/200=50\n",
        "#nb_epoch = 100\n",
        "nb_epoch = 100\n",
        "model.fit_generator(train_generator, epochs=nb_epoch, steps_per_epoch=500, validation_steps=50, validation_data=validation_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/200\n",
            "500/500 [==============================] - 305s 610ms/step - loss: 7.3617 - acc: 0.0527 - val_loss: 5.9454 - val_acc: 0.0681\n",
            "Epoch 2/200\n",
            "500/500 [==============================] - 280s 561ms/step - loss: 5.2858 - acc: 0.0919 - val_loss: 5.7669 - val_acc: 0.0569\n",
            "Epoch 3/200\n",
            "500/500 [==============================] - 279s 559ms/step - loss: 4.8125 - acc: 0.1144 - val_loss: 5.1504 - val_acc: 0.0845\n",
            "Epoch 4/200\n",
            "500/500 [==============================] - 284s 568ms/step - loss: 4.5680 - acc: 0.1342 - val_loss: 4.8802 - val_acc: 0.0984\n",
            "Epoch 5/200\n",
            "500/500 [==============================] - 283s 566ms/step - loss: 4.4311 - acc: 0.1437 - val_loss: 4.8763 - val_acc: 0.1066\n",
            "Epoch 6/200\n",
            "500/500 [==============================] - 284s 567ms/step - loss: 4.3104 - acc: 0.1596 - val_loss: 4.5245 - val_acc: 0.1305\n",
            "Epoch 7/200\n",
            "500/500 [==============================] - 284s 567ms/step - loss: 4.2099 - acc: 0.1716 - val_loss: 4.3443 - val_acc: 0.1612\n",
            "Epoch 8/200\n",
            "500/500 [==============================] - 284s 569ms/step - loss: 4.1254 - acc: 0.1840 - val_loss: 4.3682 - val_acc: 0.1617\n",
            "Epoch 9/200\n",
            "500/500 [==============================] - 284s 569ms/step - loss: 4.0499 - acc: 0.1927 - val_loss: 4.8208 - val_acc: 0.1291\n",
            "Epoch 10/200\n",
            "500/500 [==============================] - 284s 569ms/step - loss: 3.9781 - acc: 0.2078 - val_loss: 4.3894 - val_acc: 0.1696\n",
            "Epoch 11/200\n",
            "500/500 [==============================] - 283s 566ms/step - loss: 3.9289 - acc: 0.2139 - val_loss: 4.6153 - val_acc: 0.1419\n",
            "Epoch 12/200\n",
            "500/500 [==============================] - 282s 564ms/step - loss: 3.8653 - acc: 0.2237 - val_loss: 4.0693 - val_acc: 0.1926\n",
            "Epoch 13/200\n",
            "500/500 [==============================] - 281s 563ms/step - loss: 3.8087 - acc: 0.2322 - val_loss: 5.2769 - val_acc: 0.1338\n",
            "Epoch 14/200\n",
            "500/500 [==============================] - 281s 562ms/step - loss: 3.7597 - acc: 0.2414 - val_loss: 4.1056 - val_acc: 0.1934\n",
            "Epoch 15/200\n",
            "500/500 [==============================] - 282s 564ms/step - loss: 3.7174 - acc: 0.2500 - val_loss: 4.8263 - val_acc: 0.1430\n",
            "Epoch 16/200\n",
            "500/500 [==============================] - 284s 568ms/step - loss: 3.6709 - acc: 0.2563 - val_loss: 4.4330 - val_acc: 0.1747\n",
            "Epoch 17/200\n",
            "500/500 [==============================] - 284s 568ms/step - loss: 3.6291 - acc: 0.2662 - val_loss: 4.2219 - val_acc: 0.1984\n",
            "Epoch 18/200\n",
            "500/500 [==============================] - 282s 564ms/step - loss: 3.5941 - acc: 0.2711 - val_loss: 4.9910 - val_acc: 0.1606\n",
            "Epoch 19/200\n",
            "500/500 [==============================] - 283s 567ms/step - loss: 3.5602 - acc: 0.2779 - val_loss: 4.5549 - val_acc: 0.1792\n",
            "Epoch 20/200\n",
            "500/500 [==============================] - 283s 567ms/step - loss: 3.5303 - acc: 0.2822 - val_loss: 4.2201 - val_acc: 0.2086\n",
            "Epoch 21/200\n",
            "500/500 [==============================] - 282s 564ms/step - loss: 3.4991 - acc: 0.2879 - val_loss: 3.9708 - val_acc: 0.2351\n",
            "Epoch 22/200\n",
            "500/500 [==============================] - 281s 562ms/step - loss: 3.4659 - acc: 0.2955 - val_loss: 3.8813 - val_acc: 0.2566\n",
            "Epoch 23/200\n",
            "500/500 [==============================] - 281s 563ms/step - loss: 3.4396 - acc: 0.2997 - val_loss: 4.5993 - val_acc: 0.1830\n",
            "Epoch 24/200\n",
            "500/500 [==============================] - 281s 563ms/step - loss: 3.4079 - acc: 0.3073 - val_loss: 3.8949 - val_acc: 0.2482\n",
            "Epoch 25/200\n",
            "500/500 [==============================] - 282s 563ms/step - loss: 3.3875 - acc: 0.3125 - val_loss: 4.3333 - val_acc: 0.2085\n",
            "Epoch 26/200\n",
            "500/500 [==============================] - 283s 566ms/step - loss: 3.3595 - acc: 0.3179 - val_loss: 4.3561 - val_acc: 0.2091\n",
            "Epoch 27/200\n",
            "500/500 [==============================] - 282s 563ms/step - loss: 3.3350 - acc: 0.3217 - val_loss: 4.4110 - val_acc: 0.2239\n",
            "Epoch 28/200\n",
            "500/500 [==============================] - 281s 563ms/step - loss: 3.3126 - acc: 0.3254 - val_loss: 3.5936 - val_acc: 0.2981\n",
            "Epoch 29/200\n",
            "500/500 [==============================] - 281s 562ms/step - loss: 3.2912 - acc: 0.3282 - val_loss: 4.2012 - val_acc: 0.2267\n",
            "Epoch 30/200\n",
            "500/500 [==============================] - 281s 562ms/step - loss: 3.2742 - acc: 0.3323 - val_loss: 4.2108 - val_acc: 0.2217\n",
            "Epoch 31/200\n",
            "500/500 [==============================] - 281s 562ms/step - loss: 3.2552 - acc: 0.3384 - val_loss: 4.5547 - val_acc: 0.1908\n",
            "Epoch 32/200\n",
            "500/500 [==============================] - 281s 562ms/step - loss: 3.2322 - acc: 0.3430 - val_loss: 4.1337 - val_acc: 0.2328\n",
            "Epoch 33/200\n",
            "500/500 [==============================] - 281s 562ms/step - loss: 3.2173 - acc: 0.3471 - val_loss: 4.1966 - val_acc: 0.2388\n",
            "Epoch 34/200\n",
            "500/500 [==============================] - 281s 562ms/step - loss: 3.2002 - acc: 0.3500 - val_loss: 4.8429 - val_acc: 0.2017\n",
            "Epoch 35/200\n",
            "500/500 [==============================] - 281s 562ms/step - loss: 3.1880 - acc: 0.3506 - val_loss: 3.9598 - val_acc: 0.2527\n",
            "Epoch 36/200\n",
            "500/500 [==============================] - 281s 562ms/step - loss: 3.1682 - acc: 0.3551 - val_loss: 4.5242 - val_acc: 0.2017\n",
            "Epoch 37/200\n",
            "500/500 [==============================] - 281s 562ms/step - loss: 3.1505 - acc: 0.3606 - val_loss: 4.2356 - val_acc: 0.2357\n",
            "Epoch 38/200\n",
            "500/500 [==============================] - 282s 563ms/step - loss: 3.1360 - acc: 0.3601 - val_loss: 3.6264 - val_acc: 0.2910\n",
            "Epoch 39/200\n",
            "500/500 [==============================] - 282s 563ms/step - loss: 3.1228 - acc: 0.3657 - val_loss: 3.9939 - val_acc: 0.2554\n",
            "Epoch 40/200\n",
            "500/500 [==============================] - 281s 563ms/step - loss: 3.1118 - acc: 0.3666 - val_loss: 3.7131 - val_acc: 0.2912\n",
            "Epoch 41/200\n",
            "500/500 [==============================] - 282s 563ms/step - loss: 3.0936 - acc: 0.3688 - val_loss: 4.7850 - val_acc: 0.2147\n",
            "Epoch 42/200\n",
            "500/500 [==============================] - 282s 565ms/step - loss: 3.0838 - acc: 0.3729 - val_loss: 4.2241 - val_acc: 0.2427\n",
            "Epoch 43/200\n",
            "500/500 [==============================] - 282s 564ms/step - loss: 3.0759 - acc: 0.3740 - val_loss: 3.9334 - val_acc: 0.2688\n",
            "Epoch 44/200\n",
            "500/500 [==============================] - 282s 564ms/step - loss: 3.0592 - acc: 0.3777 - val_loss: 4.8769 - val_acc: 0.1933\n",
            "Epoch 45/200\n",
            "500/500 [==============================] - 283s 566ms/step - loss: 3.0426 - acc: 0.3826 - val_loss: 4.3310 - val_acc: 0.2284\n",
            "Epoch 46/200\n",
            "500/500 [==============================] - 283s 566ms/step - loss: 3.0378 - acc: 0.3839 - val_loss: 4.4834 - val_acc: 0.2382\n",
            "Epoch 47/200\n",
            "500/500 [==============================] - 283s 566ms/step - loss: 3.0264 - acc: 0.3845 - val_loss: 4.0640 - val_acc: 0.2639\n",
            "Epoch 48/200\n",
            "500/500 [==============================] - 283s 565ms/step - loss: 3.0087 - acc: 0.3885 - val_loss: 4.2996 - val_acc: 0.2480\n",
            "Epoch 49/200\n",
            "500/500 [==============================] - 283s 566ms/step - loss: 2.9978 - acc: 0.3909 - val_loss: 4.3029 - val_acc: 0.2420\n",
            "Epoch 50/200\n",
            "500/500 [==============================] - 282s 564ms/step - loss: 2.9922 - acc: 0.3934 - val_loss: 4.2029 - val_acc: 0.2602\n",
            "Epoch 51/200\n",
            "500/500 [==============================] - 284s 569ms/step - loss: 2.9734 - acc: 0.3962 - val_loss: 3.8187 - val_acc: 0.2973\n",
            "Epoch 52/200\n",
            "500/500 [==============================] - 282s 563ms/step - loss: 2.9654 - acc: 0.3969 - val_loss: 4.2188 - val_acc: 0.2549\n",
            "Epoch 53/200\n",
            "500/500 [==============================] - 282s 563ms/step - loss: 2.9607 - acc: 0.3989 - val_loss: 4.1243 - val_acc: 0.2629\n",
            "Epoch 54/200\n",
            "500/500 [==============================] - 284s 568ms/step - loss: 2.9490 - acc: 0.4026 - val_loss: 4.1933 - val_acc: 0.2738\n",
            "Epoch 55/200\n",
            "500/500 [==============================] - 283s 566ms/step - loss: 2.9360 - acc: 0.4053 - val_loss: 4.1055 - val_acc: 0.2692\n",
            "Epoch 56/200\n",
            "500/500 [==============================] - 285s 570ms/step - loss: 2.9321 - acc: 0.4067 - val_loss: 3.9204 - val_acc: 0.2825\n",
            "Epoch 57/200\n",
            "500/500 [==============================] - 286s 572ms/step - loss: 2.9246 - acc: 0.4072 - val_loss: 4.2719 - val_acc: 0.2598\n",
            "Epoch 58/200\n",
            "500/500 [==============================] - 286s 573ms/step - loss: 2.9193 - acc: 0.4072 - val_loss: 3.8381 - val_acc: 0.2985\n",
            "Epoch 59/200\n",
            "500/500 [==============================] - 286s 572ms/step - loss: 2.9098 - acc: 0.4100 - val_loss: 4.0267 - val_acc: 0.2678\n",
            "Epoch 60/200\n",
            "500/500 [==============================] - 286s 573ms/step - loss: 2.8983 - acc: 0.4122 - val_loss: 4.0306 - val_acc: 0.2828\n",
            "Epoch 61/200\n",
            "500/500 [==============================] - 282s 565ms/step - loss: 2.8915 - acc: 0.4136 - val_loss: 3.8440 - val_acc: 0.3029\n",
            "Epoch 62/200\n",
            "500/500 [==============================] - 285s 570ms/step - loss: 2.8816 - acc: 0.4168 - val_loss: 3.6509 - val_acc: 0.3164\n",
            "Epoch 63/200\n",
            "500/500 [==============================] - 286s 572ms/step - loss: 2.8721 - acc: 0.4182 - val_loss: 3.9150 - val_acc: 0.2955\n",
            "Epoch 64/200\n",
            "500/500 [==============================] - 286s 572ms/step - loss: 2.8588 - acc: 0.4191 - val_loss: 4.9113 - val_acc: 0.2168\n",
            "Epoch 65/200\n",
            "500/500 [==============================] - 287s 573ms/step - loss: 2.8610 - acc: 0.4220 - val_loss: 4.3505 - val_acc: 0.2639\n",
            "Epoch 66/200\n",
            "500/500 [==============================] - 286s 573ms/step - loss: 2.8522 - acc: 0.4232 - val_loss: 4.1706 - val_acc: 0.2730\n",
            "Epoch 67/200\n",
            "500/500 [==============================] - 287s 573ms/step - loss: 2.8378 - acc: 0.4267 - val_loss: 3.7501 - val_acc: 0.3072\n",
            "Epoch 68/200\n",
            "500/500 [==============================] - 286s 573ms/step - loss: 2.8292 - acc: 0.4261 - val_loss: 4.2430 - val_acc: 0.2493\n",
            "Epoch 69/200\n",
            "500/500 [==============================] - 286s 572ms/step - loss: 2.8260 - acc: 0.4293 - val_loss: 3.8357 - val_acc: 0.3000\n",
            "Epoch 70/200\n",
            "500/500 [==============================] - 287s 573ms/step - loss: 2.8200 - acc: 0.4309 - val_loss: 3.6999 - val_acc: 0.3216\n",
            "Epoch 71/200\n",
            "500/500 [==============================] - 286s 573ms/step - loss: 2.8129 - acc: 0.4310 - val_loss: 4.5957 - val_acc: 0.2381\n",
            "Epoch 72/200\n",
            "500/500 [==============================] - 287s 574ms/step - loss: 2.8015 - acc: 0.4345 - val_loss: 3.9752 - val_acc: 0.2908\n",
            "Epoch 73/200\n",
            "500/500 [==============================] - 287s 573ms/step - loss: 2.7984 - acc: 0.4342 - val_loss: 3.8220 - val_acc: 0.3080\n",
            "Epoch 74/200\n",
            "500/500 [==============================] - 286s 573ms/step - loss: 2.7920 - acc: 0.4356 - val_loss: 3.9632 - val_acc: 0.2936\n",
            "Epoch 75/200\n",
            "500/500 [==============================] - 286s 572ms/step - loss: 2.7849 - acc: 0.4380 - val_loss: 4.1438 - val_acc: 0.2929\n",
            "Epoch 76/200\n",
            "500/500 [==============================] - 286s 573ms/step - loss: 2.7745 - acc: 0.4400 - val_loss: 4.6615 - val_acc: 0.2477\n",
            "Epoch 77/200\n",
            "500/500 [==============================] - 287s 573ms/step - loss: 2.7753 - acc: 0.4406 - val_loss: 4.2219 - val_acc: 0.2745\n",
            "Epoch 78/200\n",
            "500/500 [==============================] - 287s 574ms/step - loss: 2.7690 - acc: 0.4401 - val_loss: 4.1399 - val_acc: 0.2715\n",
            "Epoch 79/200\n",
            "500/500 [==============================] - 287s 573ms/step - loss: 2.7649 - acc: 0.4412 - val_loss: 3.8873 - val_acc: 0.2988\n",
            "Epoch 80/200\n",
            "500/500 [==============================] - 287s 573ms/step - loss: 2.7520 - acc: 0.4446 - val_loss: 3.9810 - val_acc: 0.3076\n",
            "Epoch 81/200\n",
            "500/500 [==============================] - 287s 573ms/step - loss: 2.7515 - acc: 0.4467 - val_loss: 4.0917 - val_acc: 0.2900\n",
            "Epoch 82/200\n",
            "500/500 [==============================] - 284s 567ms/step - loss: 2.7482 - acc: 0.4466 - val_loss: 4.2977 - val_acc: 0.2712\n",
            "Epoch 83/200\n",
            "500/500 [==============================] - 283s 567ms/step - loss: 2.7355 - acc: 0.4496 - val_loss: 4.2395 - val_acc: 0.2752\n",
            "Epoch 84/200\n",
            "500/500 [==============================] - 282s 563ms/step - loss: 2.7348 - acc: 0.4493 - val_loss: 3.9227 - val_acc: 0.3022\n",
            "Epoch 85/200\n",
            "500/500 [==============================] - 281s 563ms/step - loss: 2.7202 - acc: 0.4521 - val_loss: 3.7451 - val_acc: 0.3231\n",
            "Epoch 86/200\n",
            "500/500 [==============================] - 280s 560ms/step - loss: 2.7169 - acc: 0.4543 - val_loss: 4.3072 - val_acc: 0.2714\n",
            "Epoch 87/200\n",
            "500/500 [==============================] - 279s 559ms/step - loss: 2.7094 - acc: 0.4534 - val_loss: 3.9901 - val_acc: 0.3100\n",
            "Epoch 88/200\n",
            "500/500 [==============================] - 279s 558ms/step - loss: 2.7041 - acc: 0.4560 - val_loss: 3.9899 - val_acc: 0.2970\n",
            "Epoch 89/200\n",
            "500/500 [==============================] - 280s 559ms/step - loss: 2.7010 - acc: 0.4565 - val_loss: 4.4550 - val_acc: 0.2678\n",
            "Epoch 90/200\n",
            "500/500 [==============================] - 280s 560ms/step - loss: 2.6953 - acc: 0.4580 - val_loss: 4.0844 - val_acc: 0.3067\n",
            "Epoch 91/200\n",
            "500/500 [==============================] - 280s 560ms/step - loss: 2.6881 - acc: 0.4604 - val_loss: 4.2888 - val_acc: 0.2847\n",
            "Epoch 92/200\n",
            "500/500 [==============================] - 280s 559ms/step - loss: 2.6798 - acc: 0.4608 - val_loss: 4.3080 - val_acc: 0.2813\n",
            "Epoch 93/200\n",
            "500/500 [==============================] - 279s 559ms/step - loss: 2.6873 - acc: 0.4573 - val_loss: 4.5614 - val_acc: 0.2680\n",
            "Epoch 94/200\n",
            "500/500 [==============================] - 279s 557ms/step - loss: 2.6724 - acc: 0.4615 - val_loss: 4.4986 - val_acc: 0.2684\n",
            "Epoch 95/200\n",
            "500/500 [==============================] - 279s 558ms/step - loss: 2.6674 - acc: 0.4638 - val_loss: 3.6024 - val_acc: 0.3514\n",
            "Epoch 96/200\n",
            "500/500 [==============================] - 279s 558ms/step - loss: 2.6591 - acc: 0.4665 - val_loss: 4.1203 - val_acc: 0.3075\n",
            "Epoch 97/200\n",
            "500/500 [==============================] - 279s 559ms/step - loss: 2.6602 - acc: 0.4655 - val_loss: 4.7857 - val_acc: 0.2536\n",
            "Epoch 98/200\n",
            "500/500 [==============================] - 279s 559ms/step - loss: 2.6539 - acc: 0.4662 - val_loss: 4.3324 - val_acc: 0.2829\n",
            "Epoch 99/200\n",
            "500/500 [==============================] - 279s 559ms/step - loss: 2.6486 - acc: 0.4686 - val_loss: 4.2575 - val_acc: 0.2922\n",
            "Epoch 100/200\n",
            "500/500 [==============================] - 279s 558ms/step - loss: 2.6410 - acc: 0.4717 - val_loss: 4.3627 - val_acc: 0.2756\n",
            "Epoch 101/200\n",
            "500/500 [==============================] - 279s 557ms/step - loss: 2.6378 - acc: 0.4707 - val_loss: 4.1482 - val_acc: 0.3079\n",
            "Epoch 102/200\n",
            "500/500 [==============================] - 279s 557ms/step - loss: 2.6269 - acc: 0.4739 - val_loss: 4.4958 - val_acc: 0.2826\n",
            "Epoch 103/200\n",
            "500/500 [==============================] - 279s 558ms/step - loss: 2.6279 - acc: 0.4719 - val_loss: 4.2989 - val_acc: 0.3001\n",
            "Epoch 104/200\n",
            "500/500 [==============================] - 278s 556ms/step - loss: 2.6260 - acc: 0.4732 - val_loss: 3.8375 - val_acc: 0.3306\n",
            "Epoch 105/200\n",
            "500/500 [==============================] - 277s 555ms/step - loss: 2.6189 - acc: 0.4744 - val_loss: 4.4754 - val_acc: 0.2696\n",
            "Epoch 106/200\n",
            "500/500 [==============================] - 277s 554ms/step - loss: 2.6079 - acc: 0.4782 - val_loss: 4.4558 - val_acc: 0.2859\n",
            "Epoch 107/200\n",
            "500/500 [==============================] - 277s 554ms/step - loss: 2.6075 - acc: 0.4768 - val_loss: 4.5582 - val_acc: 0.2703\n",
            "Epoch 108/200\n",
            "500/500 [==============================] - 278s 557ms/step - loss: 2.6095 - acc: 0.4763 - val_loss: 4.0277 - val_acc: 0.3117\n",
            "Epoch 109/200\n",
            "500/500 [==============================] - 279s 558ms/step - loss: 2.5995 - acc: 0.4782 - val_loss: 4.2235 - val_acc: 0.2979\n",
            "Epoch 110/200\n",
            "500/500 [==============================] - 278s 556ms/step - loss: 2.5932 - acc: 0.4809 - val_loss: 4.1410 - val_acc: 0.2902\n",
            "Epoch 111/200\n",
            "500/500 [==============================] - 278s 556ms/step - loss: 2.5868 - acc: 0.4823 - val_loss: 4.7996 - val_acc: 0.2385\n",
            "Epoch 112/200\n",
            "500/500 [==============================] - 278s 556ms/step - loss: 2.5817 - acc: 0.4824 - val_loss: 4.8097 - val_acc: 0.2538\n",
            "Epoch 113/200\n",
            "500/500 [==============================] - 278s 556ms/step - loss: 2.5826 - acc: 0.4829 - val_loss: 4.1569 - val_acc: 0.3082\n",
            "Epoch 114/200\n",
            "500/500 [==============================] - 279s 557ms/step - loss: 2.5800 - acc: 0.4839 - val_loss: 4.3356 - val_acc: 0.2826\n",
            "Epoch 115/200\n",
            "500/500 [==============================] - 277s 555ms/step - loss: 2.5663 - acc: 0.4873 - val_loss: 4.4995 - val_acc: 0.2839\n",
            "Epoch 116/200\n",
            "500/500 [==============================] - 277s 554ms/step - loss: 2.5669 - acc: 0.4865 - val_loss: 4.3575 - val_acc: 0.2774\n",
            "Epoch 117/200\n",
            "500/500 [==============================] - 278s 555ms/step - loss: 2.5657 - acc: 0.4851 - val_loss: 4.7375 - val_acc: 0.2595\n",
            "Epoch 118/200\n",
            "500/500 [==============================] - 279s 557ms/step - loss: 2.5590 - acc: 0.4871 - val_loss: 4.2663 - val_acc: 0.2966\n",
            "Epoch 119/200\n",
            "363/500 [====================>.........] - ETA: 1:14 - loss: 2.5464 - acc: 0.4914Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lao5drrHoy-d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "model_yaml = model.to_yaml()\n",
        "with open(\"session4_vkt_model240319.yaml\", \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "print('Test accuracy:', score[1])\n",
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"session4_vkt_model240319.h5\")\n",
        "print(\"Saved the model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "52Pz599rpBC9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights(\"session4_vkt_model240319.h5\")\n",
        "print(\"Saved the model to disk\")\n",
        "from google.colab import files\n",
        "files.download('session4_vkt_model240319.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}