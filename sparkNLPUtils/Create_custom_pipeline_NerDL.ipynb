{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Create custom pipeline - NerDL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY5KZWu8sYEV",
        "colab_type": "text"
      },
      "source": [
        "Show how to use pretrained assertion status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpzZuBNnKXwv",
        "colab_type": "code",
        "outputId": "d10c9067-c6c1-4b12-a3b9-80bc62163ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/Colab Notebooks/SparkNLP/utils')\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n",
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR2LZ_LQRqed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6a17fdf5-5bcc-4b47-9359-eeb15203ffb5"
      },
      "source": [
        "drivepath = \"gdrive/My Drive/Colab Notebooks/SparkNLP/utils\"\n",
        "biotrainset = \"con_rest_train.bio\"\n",
        "gloveemb = \"glove.6B.300d.txt\"\n",
        "modelsavefilename=\"ner_dl_model_aug\"\n",
        "print(\"Driver path file name :\"+biofile)\n",
        "print(\"BIO file name :\"+biotrainset)\n",
        "print(\"Glovec file name :\"+gloveemb)\n",
        "print(\"modelsavefilename file name :\"+modelsavefilename)\n",
        "!cp \"gdrive/My Drive/Colab Notebooks/SparkNLP/utils/con_rest_train.bio\" \"con_rest_train.bio\"\n",
        "!cp \"gdrive/My Drive/Colab Notebooks/SparkNLP/utils/glove.6B.300d.txt\" \"glove.6B.300d.txt\"\n",
        "!cp \"gdrive/My Drive/Colab Notebooks/SparkNLP/utils/blstm_17_300_128_37.pb\" \"blstm_17_300_128_37.pb\"\n",
        "\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Driver path file name :gdrive/My Drive/Colab Notebooks/SparkNLP/utilscon_rest_train.bio\n",
            "BIO file name :con_rest_train.bio\n",
            "Glovec file name :glove.6B.300d.txt\n",
            "modelsavefilename file name :ner_dl_model_aug\n",
            "cp: target 'biotrainset' is not a directory\n",
            "cp: cannot stat 'drivepath/glove.6B.300d.txt': No such file or directory\n",
            "cp: cannot stat 'drivepath/blstm_17_300_128_37.pb': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg_kFAOISDwZ",
        "colab_type": "code",
        "outputId": "c4c098b3-b8ce-4235-a0c8-fa8c37c9c83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "blstm_17_300_128_37.pb\tgdrive\t\t   sample_data\n",
            "con_rest_train.bio\tglove.6B.300d.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIPCfwoX_9Bo",
        "colab_type": "code",
        "outputId": "4e5c297f-891e-46e3-d5fd-e3cfc7eed325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.3\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.2.2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_222\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1ubuntu1~18.04.1-b10)\n",
            "OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode)\n",
            "Collecting pyspark==2.4.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/98/244399c0daa7894cdf387e7007d5e8b3710a79b67f3fd991c0b0b644822d/pyspark-2.4.3.tar.gz (215.6MB)\n",
            "\u001b[K     |████████████████████████████████| 215.6MB 61kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 43.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.3-py2.py3-none-any.whl size=215964963 sha256=c2bb95c3052e53e1f46a4f66717161b5dd5834ff8df05d3149f64d6cac12bce4\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/20/f0/b30e2024226dc112e256930dd2cd4f06d00ab053c86278dcf3\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.3\n",
            "Collecting spark-nlp==2.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f9/1a/711bde42e9cd17b5166a2c282ba9824103c416091c9ad95ca7dcece7170e/spark_nlp-2.2.2-py2.py3-none-any.whl\n",
            "Installing collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xco3RwJYsYEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import PipelineModel\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import ResourceDownloader\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "if sys.version_info[0] < 3:\n",
        "    from urllib import urlretrieve\n",
        "else:\n",
        "    from urllib.request import urlretrieve    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIS_nmYYsYEa",
        "colab_type": "code",
        "outputId": "9cb9bc23-9c94-47c9-d22e-2669be27b8b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Global DEMO - Spark NLP Enterprise 2.3.4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.rdd.compress\",\"true\") \\\n",
        "    .config(\"spark.driver.memory\",\"8G\") \\\n",
        "    .config(\"spark.driver.maxResultSize\", \"2G\") \\\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "    .config(\"spark.kryoserializer.buffer.max\", \"600M\") \\\n",
        "    .config(\"spark.jars.packages\", \"JohnSnowLabs:spark-nlp:2.3.4\") \\\n",
        "    .getOrCreate()\n",
        "#spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.2\n",
            "Spark NLP version:  None\n",
            "Apache Spark version:  2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPPQJS2CsYEc",
        "colab_type": "text"
      },
      "source": [
        "Create some data for testing purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZegTIiC0sYEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import Row\n",
        "R = Row('sentence', 'start', 'end')\n",
        "test_data = spark.createDataFrame([R('Peter is a good person, and he was working at IBM',0,1)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ3gvJQHsYEf",
        "colab_type": "text"
      },
      "source": [
        "Create a custom pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyzLAY_RDPc7",
        "colab_type": "code",
        "outputId": "311af7ea-bf5d-4567-b635-3a58f6cd3313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!ls\n",
        "from sparknlp.training import CoNLL\n",
        "training_data = CoNLL().readDataset(spark, 'con_rest_train.bio')\n",
        "training_data.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "blstm_17_300_128_37.pb\tgdrive\t\t   sample_data\n",
            "con_rest_train.bio\tglove.6B.300d.txt\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|2 star restaurant...|[[document, 0, 38...|[[document, 0, 36...|[[token, 0, 0, 2,...|[[pos, 0, 0, , [w...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGWDh6y7sYEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "embeddings = WordEmbeddings() \\\n",
        "        .setInputCols([\"document\", \"token\"])\\\n",
        "        .setOutputCol(\"embeddings\")\\\n",
        "        .setEmbeddingsSource(\"glove.6B.300d.txt\", 300, \"text\")\n",
        "\n",
        "#spell = NorvigSweetingModel.pretrained() \\\n",
        "#    .setInputCols([\"token\"]) \\\n",
        "#    .setOutputCol(\"spell\")\n",
        "\n",
        "ner_dl = NerDLApproach()\\\n",
        "    .setInputCols([\"document\", \"token\",\"embeddings\"])\\\n",
        "    .setLabelColumn(\"label\")\\\n",
        "    .setOutputCol(\"ner\")\\\n",
        "    .setMaxEpochs(2)\\\n",
        "    .setRandomSeed(0)\\\n",
        "    .setVerbose(2)\\\n",
        "    .setBatchSize(9)\\\n",
        "    .setGraphFolder(\"gdrive/My Drive/Colab Notebooks/SparkNLP/utils/Graphs\")\\\n",
        "    .setEnableOutputLogs(True)\n",
        "\n",
        "converter = NerConverter()\\\n",
        "  .setInputCols([\"document\", \"token\", \"ner\"])\\\n",
        "  .setOutputCol(\"ner_converter\")\n",
        "\n",
        "finisher = Finisher() \\\n",
        "    .setInputCols([\"ner\", \"ner_converter\"]) \\\n",
        "    .setIncludeMetadata(True)\n",
        "\n",
        "pipeline_fast_dl = Pipeline(stages = [\n",
        "    documentAssembler, \n",
        "    tokenizer, \n",
        "    embeddings, \n",
        "    ner_dl,\n",
        "    converter,\n",
        "    finisher])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m8RfeZZsYEi",
        "colab_type": "text"
      },
      "source": [
        "Now let's use these pipelines and see the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO_qeaCQDcDC",
        "colab_type": "code",
        "outputId": "b1e5456b-2498-4455-b852-af7936a3cd12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "start = time.time()\n",
        "print(\"Start fitting\")\n",
        "prediction_model = pipeline_fast_dl.fit(training_data)\n",
        "print(\"Fitting is ended\")\n",
        "print (time.time() - start)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start fitting\n",
            "Fitting is ended\n",
            "912.3336133956909\n",
            "CPU times: user 218 ms, sys: 56.4 ms, total: 275 ms\n",
            "Wall time: 15min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK-J83PbffUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "3215d28e-141e-4f5e-f2d7-9e2a72f25e7e"
      },
      "source": [
        "prediction_data = spark.createDataFrame([[\"Maria is a nice place.\"],[\"any bbq places open before 5 nearby\"]]).toDF(\"text\")\n",
        "prediction_data.show()\n",
        "prediction_model.transform(prediction_data).show(truncate=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|Maria is a nice p...|\n",
            "|any bbq places op...|\n",
            "+--------------------+\n",
            "\n",
            "+-----------------------------------+---------------------+----------------------+---------------------------------------------------------------------------------------------------+-------------------------------+\n",
            "|text                               |finished_ner         |finished_ner_converter|finished_ner_metadata                                                                              |finished_ner_converter_metadata|\n",
            "+-----------------------------------+---------------------+----------------------+---------------------------------------------------------------------------------------------------+-------------------------------+\n",
            "|Maria is a nice place.             |[O, O, O, O, O, O]   |[]                    |[[word, Maria], [word, is], [word, a], [word, nice], [word, place], [word, .]]                     |[]                             |\n",
            "|any bbq places open before 5 nearby|[O, O, O, O, O, O, O]|[]                    |[[word, any], [word, bbq], [word, places], [word, open], [word, before], [word, 5], [word, nearby]]|[]                             |\n",
            "+-----------------------------------+---------------------+----------------------+---------------------------------------------------------------------------------------------------+-------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ov6Vcf2ERg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_model.write().overwrite().save(\"ner_dl_model_aug\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4TsjFNr3xJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r 'ner_dl_model_aug' 'gdrive/My Drive/Colab Notebooks/SparkNLP/utils/ner_dl_model_aug'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86pAku0iETDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml import PipelineModel, Pipeline\n",
        "\n",
        "loaded_prediction_model = PipelineModel.read().load(ner_dl_model_aug)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqO9vjyZGMzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "bf88ea83-f38e-47cc-af7d-b9013a952551"
      },
      "source": [
        "prediction_data = spark.createDataFrame([[\"Maria is a nice place.\"],[\"any bbq places open before 5 nearby\"],[\"2 star restaurants with inside dining\"]]).toDF(\"text\")\n",
        "prediction_data.show()\n",
        "loaded_prediction_model.transform(prediction_data).show(truncate=False)\n",
        "prediction = loaded_prediction_model.transform(prediction_data)\n",
        "prediction.select(\"finished_ner_metadata\").show(truncate=False)\n",
        "prediction.select(\"finished_ner\").show(truncate=False)\n",
        "prediction.select(\"finished_ner_converter_metadata\").show(truncate=False)\n",
        "prediction.select(\"finished_ner_converter\").show(truncate=False)\n",
        "#prediction.select(\"ner\").show(truncate=False)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|Maria is a nice p...|\n",
            "|any bbq places op...|\n",
            "|2 star restaurant...|\n",
            "+--------------------+\n",
            "\n",
            "+-------------------------------------+---------------------+----------------------+---------------------------------------------------------------------------------------------------+-------------------------------+\n",
            "|text                                 |finished_ner         |finished_ner_converter|finished_ner_metadata                                                                              |finished_ner_converter_metadata|\n",
            "+-------------------------------------+---------------------+----------------------+---------------------------------------------------------------------------------------------------+-------------------------------+\n",
            "|Maria is a nice place.               |[O, O, O, O, O, O]   |[]                    |[[word, Maria], [word, is], [word, a], [word, nice], [word, place], [word, .]]                     |[]                             |\n",
            "|any bbq places open before 5 nearby  |[O, O, O, O, O, O, O]|[]                    |[[word, any], [word, bbq], [word, places], [word, open], [word, before], [word, 5], [word, nearby]]|[]                             |\n",
            "|2 star restaurants with inside dining|[O, O, O, O, O, O]   |[]                    |[[word, 2], [word, star], [word, restaurants], [word, with], [word, inside], [word, dining]]       |[]                             |\n",
            "+-------------------------------------+---------------------+----------------------+---------------------------------------------------------------------------------------------------+-------------------------------+\n",
            "\n",
            "+---------------------------------------------------------------------------------------------------+\n",
            "|finished_ner_metadata                                                                              |\n",
            "+---------------------------------------------------------------------------------------------------+\n",
            "|[[word, Maria], [word, is], [word, a], [word, nice], [word, place], [word, .]]                     |\n",
            "|[[word, any], [word, bbq], [word, places], [word, open], [word, before], [word, 5], [word, nearby]]|\n",
            "|[[word, 2], [word, star], [word, restaurants], [word, with], [word, inside], [word, dining]]       |\n",
            "+---------------------------------------------------------------------------------------------------+\n",
            "\n",
            "+---------------------+\n",
            "|finished_ner         |\n",
            "+---------------------+\n",
            "|[O, O, O, O, O, O]   |\n",
            "|[O, O, O, O, O, O, O]|\n",
            "|[O, O, O, O, O, O]   |\n",
            "+---------------------+\n",
            "\n",
            "+-------------------------------+\n",
            "|finished_ner_converter_metadata|\n",
            "+-------------------------------+\n",
            "|[]                             |\n",
            "|[]                             |\n",
            "|[]                             |\n",
            "+-------------------------------+\n",
            "\n",
            "+----------------------+\n",
            "|finished_ner_converter|\n",
            "+----------------------+\n",
            "|[]                    |\n",
            "|[]                    |\n",
            "|[]                    |\n",
            "+----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcqxPV5vGIyI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "7f491c36-0fac-4902-bc23-3a46bdbc3b00"
      },
      "source": [
        "from sparknlp.base import LightPipeline\n",
        "\n",
        "lp = LightPipeline(loaded_prediction_model)\n",
        "result = lp.annotate(\"Peter is a good person.\")\n",
        "for e in list(zip(result['token'], result['ner']))[:10]:\n",
        "    print(e)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-b53a68e676a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msparknlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLightPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_prediction_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Peter is a good person.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ner'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sparknlp/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pipelineModel)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipelineModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipelineModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightPipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LightPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipelineModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sparknlp/internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pipelineModel)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_LightPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExtendedJavaWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipelineModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LightPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"com.johnsnowlabs.nlp.LightPipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipelineModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sparknlp/internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, java_obj, *args)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExtendedJavaWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sparknlp/internal.py\u001b[0m in \u001b[0;36mnew_java_obj\u001b[0;34m(self, java_class, *args)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_java_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpylist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1525\u001b[0;31m             answer, self._gateway_client, None, self._fqn)\n\u001b[0m\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n\u001b[1;32m    331\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                     format(target_id, \".\", name, value))\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             raise Py4JError(\n",
            "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling None.com.johnsnowlabs.nlp.LightPipeline. Trace:\npy4j.Py4JException: Constructor com.johnsnowlabs.nlp.LightPipeline([class org.apache.spark.ml.PipelineModel]) does not exist\n\tat py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:179)\n\tat py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:196)\n\tat py4j.Gateway.invoke(Gateway.java:237)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX3Jx3vJGI-u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "ce96f9c7-5ba4-4b2a-a2c2-8d5bcd25e05f"
      },
      "source": [
        "for stage in loaded_prediction_model.stages:\n",
        "    print(stage)\n",
        "print(loaded_prediction_model.stages[-1].stages)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DocumentAssembler_44ad655ebd78\n",
            "REGEX_TOKENIZER_62aa1d44b242\n",
            "WORD_EMBEDDINGS_MODEL_31fbcf792801\n",
            "NerDLModel_41805337f0d2\n",
            "NerConverter_04d283d06e00\n",
            "Finisher_11c085484ffc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-d8ec865285e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_prediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_prediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Finisher' object has no attribute 'stages'"
          ]
        }
      ]
    }
  ]
}